{
 "cells": [
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# Common data problems"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data type constraints"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. Course outline\n",
    "\n",
    "In this course, we're going to understand how to diagnose different problems in our data and how they can can come up during our workflow."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Course outline\n",
    "\n",
    "We will also understand the side effects of not treating our data correctly."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Course outline\n",
    "\n",
    "and various ways to address different types of dirty data."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. Course outline\n",
    "\n",
    "In this chapter, we're going to discuss the most common data problems you may encounter and how to address them. So let's get started!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. Why do we need to clean data?\n",
    "\n",
    "To understand why we need to clean data, let's remind ourselves of the data science workflow. In a typical data science workflow, we usually access our raw data, explore and process it, develop insights using visualizations or predictive models, and finally report these insights with dashboards or reports."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. Why do we need to clean data?\n",
    "\n",
    "Dirty data can appear because of duplicate values, mis-spellings, data type parsing errors and legacy systems."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. Why do we need to clean data?\n",
    "\n",
    "Without making sure that data is properly cleaned in the exploration and processing phase, we will surely compromise the insights and reports subsequently generated. As the old adage says, garbage in garbage out.\n",
    "<img src=\"image/img.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. Data type constraints\n",
    "\n",
    "When working with data, there are various types that we may encounter along the way. We could be working with text data, integers, decimals, dates, zip codes, and others. Luckily, Python has specific data type objects for various data types that you're probably familiar with by now. This makes it much easier to manipulate these various data types in Python. As such, before preparing to analyze and extract insights from our data, we need to make sure our variables have the correct data types, other wise we risk compromising our analysis."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. Strings to integers\n",
    "\n",
    "Let's take a look at the following example. Here's the head of a DataFrame containing revenue generated and quantity of items sold for a sales order. We want to calculate the total revenue generated by all sales orders. As you can see, the Revenue column has the dollar sign on the right hand side. A close inspection of the DataFrame column's data types using the dot-dtypes attribute returns object for the Revenue column, which is what pandas uses to store strings."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 11. String to integers\n",
    "\n",
    "We can also check the data types as well as the number of missing values per column in a DataFrame, by using the dot-info() method."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 12. String to integers\n",
    "\n",
    "Since the Revenue column is a string, summing across all sales orders returns one large concatenated string containing each row's string. To fix this, we need to first remove the $ sign from the string so that pandas is able to convert the strings into numbers without error. We do this with the dot-str-dot-strip() method, while specifying the string we want to strip as an argument, which is in this case the dollar sign. Since our dollar values do not contain decimals, we then convert the Revenue column to an integer by using the dot-astype() method, specifying the desired data type as argument. Had our revenue values been decimal, we would have converted the Revenue column to float. We can make sure that the Revenue column is now an integer by using the assert statement, which takes in a condition as input, as returns nothing if that condition is met, and an error if it is not."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 13. The assert statement\n",
    "\n",
    "For example, here we are testing the equality that 1+1 equals 2. Since it is the case, the assert statement returns nothing. However, when testing the equality 1+1 equals 3, we receive an assertionerror. You can test almost anything you can imagine of by using assert, and we'll see more ways to utilize it as we go along the course."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 14. Numeric or categorical?\n",
    "\n",
    "A common type of data seems numeric but actually represents categories with a finite set of possible categories. This is called categorical data. We will look more closely at categorical data in Chapter 2, but let's take a look at this example. Here we have a marriage status column, which is represented by 0 for never married, 1 for married, 2 for separated, and 3 for divorced. However it will be imported of type integer, which could lead to misleading results when trying to extract some statistical summaries."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 15. Numeric or categorical?\n",
    "\n",
    "We can solve this by using the same dot-astype() method seen earlier, but this time specifying the category data type. When applying the describe again, we see that the summary statistics are much more aligned with that of a categorical variable, discussing the number of observations, number of unique values, most frequent category instead of mean and standard deviation."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 16. Let's practice!\n",
    "\n",
    "Now that we have a solid understanding of data type constrains - let's get to practice!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Numeric data or ... ?\n",
    "\n",
    "<p>In this exercise, and throughout this chapter, you'll be working with bicycle ride sharing data in San Francisco called <code>ride_sharing</code>. It contains information on the start and end stations, the trip duration, and some user information for a bike sharing service. </p>\n",
    "<p>The <code>user_type</code> column contains information on whether a user is taking a free ride and takes on the following values:</p>\n",
    "<ul>\n",
    "<li><code>1</code> for free riders.</li>\n",
    "<li><code>2</code> for pay per ride.</li>\n",
    "<li><code>3</code> for monthly subscribers.</li>\n",
    "</ul>\n",
    "<p>In this instance, you will print the information of <code>ride_sharing</code> using <code>.info()</code> and see a firsthand example of how an incorrect data type can flaw your analysis of the dataset. The <code>pandas</code> package is imported as <code>pd</code>.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "(25760, 11)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ride_sharing = pd.read_csv(\"data/ride_sharing_new.csv\",index_col=0)\n",
    "ride_sharing.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Print the information of <code>ride_sharing</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     duration  station_A_id  \\\n0  12 minutes            81   \n1  24 minutes             3   \n2   8 minutes            67   \n3   4 minutes            16   \n4  11 minutes            22   \n\n                                      station_A_name  station_B_id  \\\n0                                 Berry St at 4th St           323   \n1       Powell St BART Station (Market St at 4th St)           118   \n2  San Francisco Caltrain Station 2  (Townsend St...            23   \n3                            Steuart St at Market St            28   \n4                              Howard St at Beale St           350   \n\n                    station_B_name  bike_id   user_type  user_birth_year  \\\n0               Broadway at Kearny     5480  Subscriber             1959   \n1  Eureka Valley Recreation Center     5193  Subscriber             1965   \n2    The Embarcadero at Steuart St     3652  Subscriber             1993   \n3     The Embarcadero at Bryant St     1883  Subscriber             1979   \n4             8th St at Brannan St     4626  Subscriber             1994   \n\n  user_gender  tire_sizes   ride_date  \n0        Male        27.0  2020-01-19  \n1        Male        26.0  2018-10-24  \n2        Male        26.0  2017-12-25  \n3        Male        29.0  2023-08-11  \n4        Male        27.0  2019-01-29  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>station_A_id</th>\n      <th>station_A_name</th>\n      <th>station_B_id</th>\n      <th>station_B_name</th>\n      <th>bike_id</th>\n      <th>user_type</th>\n      <th>user_birth_year</th>\n      <th>user_gender</th>\n      <th>tire_sizes</th>\n      <th>ride_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12 minutes</td>\n      <td>81</td>\n      <td>Berry St at 4th St</td>\n      <td>323</td>\n      <td>Broadway at Kearny</td>\n      <td>5480</td>\n      <td>Subscriber</td>\n      <td>1959</td>\n      <td>Male</td>\n      <td>27.0</td>\n      <td>2020-01-19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24 minutes</td>\n      <td>3</td>\n      <td>Powell St BART Station (Market St at 4th St)</td>\n      <td>118</td>\n      <td>Eureka Valley Recreation Center</td>\n      <td>5193</td>\n      <td>Subscriber</td>\n      <td>1965</td>\n      <td>Male</td>\n      <td>26.0</td>\n      <td>2018-10-24</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8 minutes</td>\n      <td>67</td>\n      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n      <td>23</td>\n      <td>The Embarcadero at Steuart St</td>\n      <td>3652</td>\n      <td>Subscriber</td>\n      <td>1993</td>\n      <td>Male</td>\n      <td>26.0</td>\n      <td>2017-12-25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4 minutes</td>\n      <td>16</td>\n      <td>Steuart St at Market St</td>\n      <td>28</td>\n      <td>The Embarcadero at Bryant St</td>\n      <td>1883</td>\n      <td>Subscriber</td>\n      <td>1979</td>\n      <td>Male</td>\n      <td>29.0</td>\n      <td>2023-08-11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11 minutes</td>\n      <td>22</td>\n      <td>Howard St at Beale St</td>\n      <td>350</td>\n      <td>8th St at Brannan St</td>\n      <td>4626</td>\n      <td>Subscriber</td>\n      <td>1994</td>\n      <td>Male</td>\n      <td>27.0</td>\n      <td>2019-01-29</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25760 entries, 0 to 25759\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   duration         25760 non-null  object \n",
      " 1   station_A_id     25760 non-null  int64  \n",
      " 2   station_A_name   25760 non-null  object \n",
      " 3   station_B_id     25760 non-null  int64  \n",
      " 4   station_B_name   25760 non-null  object \n",
      " 5   bike_id          25760 non-null  int64  \n",
      " 6   user_type        25760 non-null  object \n",
      " 7   user_birth_year  25760 non-null  int64  \n",
      " 8   user_gender      25760 non-null  object \n",
      " 9   tire_sizes       25760 non-null  float64\n",
      " 10  ride_date        25760 non-null  object \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ride_sharing.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Use <code>.describe()</code> to print the summary statistics of the <code>user_type</code> column from <code>ride_sharing</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "count          25760\nunique             2\ntop       Subscriber\nfreq           23209\nName: user_type, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing[\"user_type\"].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Convert user_type from integer to category\n",
    "ride_sharing[\"user_type_cat\"] = ride_sharing[\"user_type\"].astype(\"category\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Write an assert statement confirming the change\n",
    "assert ride_sharing[\"user_type_cat\"].dtype == \"category\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count          25760\n",
      "unique             2\n",
      "top       Subscriber\n",
      "freq           23209\n",
      "Name: user_type_cat, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ride_sharing[\"user_type_cat\"].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Summing strings and concatenating numbers\n",
    "\n",
    "<p>In the previous exercise, you were able to identify that <code>category</code> is the correct data type for <code>user_type</code> and convert it in order to extract relevant statistical summaries that shed light on the distribution of <code>user_type</code>. </p>\n",
    "<p>Another common data type problem is importing what should be numerical values as strings, as mathematical operations such as summing and multiplication lead to string concatenation, not numerical outputs. </p>\n",
    "<p>In this exercise, you'll be converting the string column <code>duration</code> to the type <code>int</code>. Before that however, you will need to make sure to strip <code>\"minutes\"</code> from the column in order to make sure <code>pandas</code> reads it as numerical. The <code>pandas</code> package has been imported as <code>pd</code>.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Use the <code>.strip()</code> method to strip <code>duration</code> of <code>\"minutes\"</code> and store it in the <code>duration_trim</code> column."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Strip duration of minutes\n",
    "ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip(\"minutes\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert <code>duration_trim</code> to <code>int</code> and store it in the <code>duration_time</code> column."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "# Convert duration to integer\n",
    "ride_sharing['duration_time'] = ride_sharing[\"duration_trim\"].astype(\"int\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write an <code>assert</code> statement that checks if <code>duration_time</code>'s <strong>d</strong>ata <strong>type</strong> is now an <code>int</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "# Write an assert statement making sure of conversion\n",
    "assert ride_sharing['duration_time'].dtype == 'int'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the average ride duration."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         duration duration_trim  duration_time\n",
      "0      12 minutes           12              12\n",
      "1      24 minutes           24              24\n",
      "2       8 minutes            8               8\n",
      "3       4 minutes            4               4\n",
      "4      11 minutes           11              11\n",
      "...           ...           ...            ...\n",
      "25755  11 minutes           11              11\n",
      "25756  10 minutes           10              10\n",
      "25757  14 minutes           14              14\n",
      "25758  14 minutes           14              14\n",
      "25759  29 minutes           29              29\n",
      "\n",
      "[25760 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print formed columns and calculate average ride duration\n",
    "print(ride_sharing[['duration','duration_trim','duration_time']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.389052795031056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ride_sharing[\"duration_time\"].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Data range constraints"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Data range constraints\n",
    "\n",
    "Hi and welcome back! In this lesson, we're going to discuss data that should fall within a range."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. Motivation\n",
    "\n",
    "Let's first start off with some motivation. Imagine we have a dataset of movies with their respective average rating from a streaming service. The rating can be any integer between 1 an 5.\n",
    "\n",
    "<img src=\"image/img_1.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Motivation\n",
    "\n",
    "After creating a histogram with maptlotlib, we see that there are a few movies with an average rating of 6, which is well above the allowable range. This is most likely an error in data collection or parsing, where a variable is well beyond its range and treating it is essential to have accurate analysis.\n",
    "\n",
    "<img src=\"image/img_2.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Motivation\n",
    "\n",
    "Here's another example, where we see subscription dates in the future for a service. Inherently this doesn't make any sense, as we cannot sign up for a service in the future, but these errors exist either due to technical or human error. We use the datetime package's dot-date-dot-today() function to get today's date, and we filter the dataset by any subscription date higher than today's date. We need to pay attention to the range of our data.\n",
    "\n",
    "<br>\n",
    "<img src=\"image/img_3.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. How to deal with out of range data?\n",
    "\n",
    "There's a variety of options to deal with out of range data. The simplest option is to drop the data. However, depending on the size of your out of range data, you could be losing out on essential information. As a rule of thumb, only drop data when a small proportion of your dataset is affected by out of range values, however you really need to understand your dataset before deciding to drop values. Another option would be setting custom minimums or maximums to your columns. We could also set the data to missing, and impute it, but we'll take a look at how to deal with missing data in Chapter 3. We could also, dependent on the business assumptions behind our data, assign a custom value for any values of our data that go beyond a certain range.\n",
    "<br>\n",
    "<img src=\"image/img_4.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. Movie example\n",
    "\n",
    "Let's take a look at the movies example mentioned earlier. We first isolate the movies with ratings higher than 5. Now if these values are affect a small set of our data, we can drop them. We can drop them in two ways - we can either create a new filtered movies DataFrame where we only keep values of avg_rating lower or equal than to 5. Or drop the values by using the drop method. The drop method takes in as argument the row indices of movies for which the avg_rating is higher than 5. We set the inplace argument to True so that values are dropped in place and we don't have to create a new column. We can make sure this is set in place using an assert statement that checks if the maximum of avg_rating is lower or equal than to 5.\n",
    "<br>\n",
    "<img src=\"image/img_6.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. Movie example\n",
    "\n",
    "Depending on the assumptions behind our data, we can also change the out of range values to a hard limit. For example, here we're setting any value of the avg_rating column in to 5 if it goes beyond it. We can do this using the dot-loc method, which returns all cells that fit a custom row and column index. It takes as first argument the row index, or here all instances of avg_rating above 5 and as second argument the column index, which is here the avg_rating column. Again, we can make sure that this change was done using an assert statement.\n"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. Date range example\n",
    "\n",
    "Let's take another look at the date range example mentioned earlier, where we had subscriptions happening in the future. We first look at the data types of the column with the dot-dtypes attribute. We can confirm that the subscription_date column is an object and not a date or datetime object. To compare a pandas object to a date, the first step is to convert it to another date. We do so by first converting it into a pandas datetime object with the to_datetime function from pandas, which takes in as an argument the column we want to convert. We then need to convert the datetime object into a date. This conversion is done by appending dt-dot-date to the code. Could we have converted from an object directly to a date, without the pandas datetime conversion in the middle? Yes! But we'd have had to provide information about the date's format as a string, so it's just as easy to do it this way.\n",
    "<br>\n",
    "<img src=\"image/img_7.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. Date range example\n",
    "\n",
    "Now that the column is a date, we can treat it in a variety of ways. We first create a today_date variable using the datetime function date-dot-today, which allows us to store today's date. We can then either drop the rows with exceeding dates similar to how we did in the average rating example, or replace exceeding values with today's date. In both cases we can use the assert statement to verify our treatment went well, by comparing the maximum value in the subscription_date column. However, make sure to chain it with the dot-date method to return a date instead of a timestamp.\n",
    "<br>\n",
    "<img src=\"image/img_8.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. Let's practice!\n",
    "\n",
    "Now that you know all about ranges, let's practice!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Tire size constraints\n",
    "\n",
    "<p>In this lesson, you're going to build on top of the work you've been doing with the <code>ride_sharing</code> DataFrame. You'll be working with the <code>tire_sizes</code> column which contains data on each bike's tire size. </p>\n",
    "<p>Bicycle tire sizes could be either 26″, 27″ or 29″ and are here correctly stored as a categorical value. In an effort to cut maintenance costs, the ride sharing provider decided to set the maximum tire size to be 27″. </p>\n",
    "<p>In this exercise, you will make sure the <code>tire_sizes</code> column has the correct range by first converting it to an integer, then setting and testing the new upper limit of 27″ for tire sizes.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Convert the <code>tire_sizes</code> column from <code>category</code> to <code>'int'</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Convert tire_sizes to integer\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('int')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use <code>.loc[]</code> to set all values of <code>tire_sizes</code> above 27 to 27."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "# Set all values above 27 to 27\n",
    "ride_sharing.loc[ride_sharing[\"tire_sizes\"] > 27, \"tire_sizes\"] = 27"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reconvert back <code>tire_sizes</code> to <code>'category'</code> from <code>int</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "# Reconvert tire_sizes back to categorical\n",
    "ride_sharing['tire_sizes'] = ride_sharing[\"tire_sizes\"].astype(\"category\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the description of the <code>tire_sizes</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     25760\n",
      "unique        2\n",
      "top          27\n",
      "freq      13274\n",
      "Name: tire_sizes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print tire size description\n",
    "print(ride_sharing['tire_sizes'].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Back to the future\n",
    "\n",
    "<p>A new update to the data pipeline feeding into the <code>ride_sharing</code> DataFrame has been updated to register each ride's date. This information is stored in the <code>ride_date</code> column of the type <code>object</code>, which represents strings in <code>pandas</code>. </p>\n",
    "<p>A bug was discovered which was relaying rides taken today as taken next year. To fix this, you will find all instances of the <code>ride_date</code> column that occur anytime in the future, and set the maximum possible value of this column to today's date. Before doing so, you would need to convert <code>ride_date</code> to a <code>datetime</code> object.</p>\n",
    "<p>The <code>datetime</code> package has been imported as <code>dt</code>, alongside all the packages you've been using till now.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert <code>ride_date</code> to a <code>datetime</code> object using <code>to_datetime()</code>, then convert the <code>datetime</code> object into a <code>date</code> and store it in <code>ride_dt</code> column."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# convert ride_date to date\n",
    "ride_sharing[\"ride_dt\"] =  pd.to_datetime(ride_sharing[\"ride_date\"]).dt.date\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the variable <code>today</code>, which stores today's date by using the <code>dt.date.today()</code> function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "# save todays date\n",
    "today = dt.date.today()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For all instances of <code>ride_dt</code> in the future, set them to today's date."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "# set all the future date to today date\n",
    "ride_sharing.loc[ride_sharing[\"ride_dt\"] > today ,\"ride_dt\"] = today"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the maximum date in the <code>ride_dt</code> column."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(ride_sharing[\"ride_dt\"].max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Uniqueness constraints"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Uniqueness constraints\n",
    "\n",
    "Hi and welcome to the final lesson of this chapter. Let's discuss another common data cleaning problem, duplicate values."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. What are duplicate values?\n",
    "\n",
    "Duplicate values can be diagnosed when we have the same exact information repeated across multiple rows, for a some or all columns in our DataFrame. In this example DataFrame containing the names, address, height, and weight of individuals, the rows presented have identical values across all columns."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. What are duplicate values?\n",
    "\n",
    "In this one, there are duplicate values for all columns except the height column -- which leads us to think it's more likely a data entry error than an actual other person."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Why do they happen?\n",
    "\n",
    "Apart from data entry and human errors alluded to in the previous slide,"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. Why do they happen?\n",
    "\n",
    "duplicate data can also arise because of bugs and design errors whether in business processes or data pipelines."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. Why do they happen?\n",
    "\n",
    "However they oftenmost arise from the necessary act of joining and consolidating data from various resources, which could retain duplicate values."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. How to find duplicate values?\n",
    "\n",
    "Let's first see how to find duplicate values. In this example, we're working with a bigger version of the the height and weight data seen earlier in the video."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. How to find duplicate values?\n",
    "\n",
    "We can find duplicates in a DataFrame by using the dot-duplicated() method. It returns a Series of boolean values that are True for duplicate values, and False for non-duplicated values."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. How to find duplicate values?\n",
    "\n",
    "We can see exactly which rows are affected by using brackets as such. However, using dot-duplicated() without playing around with the arguments of the method can lead to misleading results, as all the columns are required to have duplicate values by default, with all duplicate values being marked as True except for the first occurrence. This limits our ability to properly diagnose what type of duplication we have, and how to effectively treat it."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. How to find duplicate rows?\n",
    "\n",
    "To properly calibrate how we go about finding duplicates, we will use 2 arguments from the dot-duplicated() method. The subset argument lets us set a list of column names to check for duplication. For example, it allows us to find duplicates for the first and last name columns only. The keep argument lets us keep the first occurrence of a duplicate value by setting it to the string first, the last occurrence of a duplicate value by setting it the string last, or keep all occurrences of duplicate values by setting it to False. In this example, we're checking for duplicates across the first name, last name, and address variables, and we're choosing to keep all duplicates."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 11. How to find duplicate rows?\n",
    "\n",
    "We see the following results -- to get a better bird's eye view of the duplicates,"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 12. How to find duplicate rows?\n",
    "\n",
    "We sort the duplicate rows using the dot-sort_values method, choosing first_name to sort by."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 13. How to find duplicate rows?\n",
    "\n",
    "We find that there are four sets of duplicated rows, the first 2 being complete duplicates of each other across all columns, highlighted here in red."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 14. How to find duplicate rows?\n",
    "\n",
    "The other 2 being incomplete duplicates of each other highlighted here in blue with discrepancies across height and weight respectively."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 15. How to treat duplicate values?\n",
    "\n",
    "The complete duplicates can be treated easily. All that is required is to keep one of them only and discard the others."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 16. How to treat duplicate values?\n",
    "\n",
    "This can be done with the dot-drop_duplicates() method, which also takes in the same subset and keep arguments as in the dot-duplicated() method, as well as the inplace argument which drops the duplicated values directly inside the height_weight DataFrame. Here we are dropping complete duplicates only, so it's not necessary nor advisable to set a subset, and since the keep argument takes in first as default, we can keep it as such. Note that we can also set it as last, but not as False as it would keep all duplicates."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 17. How to treat duplicate values?\n",
    "\n",
    "This leaves us with the other 2 sets of duplicates discussed earlier, which are the same for first_name, last_name and address, but contain discrepancies in height and weight. Apart from dropping rows with really small discrepancies, we can use a statistical measure to combine each set of duplicated values."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 18. How to treat duplicate values?\n",
    "\n",
    "For example, we can combine these two rows into one by computing the average mean between them, or the maximum, or other statistical measures, this is highly dependent on a common sense understanding of our data, and what type of data we have."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 19. How to treat duplicate values?\n",
    "\n",
    "We can do this easily using the groupby method, which when chained with the agg method, lets you group by a set of common columns and return statistical values for specific columns when the aggregation is being performed. For example here, we created a dictionary called summaries, which instructs groupby to return the maximum of duplicated rows for the height column, and the mean duplicated rows for the weight column. We then group height_weight by the column names defined earlier, and chained it with the agg method, which takes in the summaries dictionary we created. We chain this entire line with the dot-reset_index() method, so that we can have numbered indices in the final output. We can verify that there are no more duplicate values by running the duplicated method again, and use brackets to output duplicate rows."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 20. Let's practice!\n",
    "\n",
    "Now that we have a solid grasp of duplication, let's practice."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Finding duplicates\n",
    "\n",
    "<p>A new update to the data pipeline feeding into <code>ride_sharing</code> has added the <code>ride_id</code> column, which represents a unique identifier for each ride. </p>\n",
    "<p>The update however coincided with radically shorter average ride duration times and irregular user birth dates set in the future. Most importantly, the number of rides taken has increased by 20% overnight, leading you to think there might be both complete and incomplete duplicates in the <code>ride_sharing</code> DataFrame. </p>\n",
    "<p>In this exercise, you will confirm this suspicion by finding those duplicates. A sample of <code>ride_sharing</code> is in your environment, as well as all the packages you've been working with thus far.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "   ride_id  duration  station_A_id  \\\n0        0        11            16   \n1        1         8             3   \n2        2        11            15   \n3        3         7            21   \n4        4        11            81   \n\n                                      station_A_name  station_B_id  \\\n0                            Steuart St at Market St            93   \n1       Powell St BART Station (Market St at 4th St)            93   \n2  San Francisco Ferry Building (Harry Bridges Pl...            67   \n3   Montgomery St BART Station (Market St at 2nd St)            50   \n4                                 Berry St at 4th St            21   \n\n                                      station_B_name  bike_id   user_type  \\\n0                       4th St at Mission Bay Blvd S     5504  Subscriber   \n1                       4th St at Mission Bay Blvd S     2915  Subscriber   \n2  San Francisco Caltrain Station 2  (Townsend St...     5340    Customer   \n3                              2nd St at Townsend St      746  Subscriber   \n4   Montgomery St BART Station (Market St at 2nd St)     5477  Subscriber   \n\n   user_birth_year user_gender  tire_sizes   ride_date  \n0             1988        Male          27  2018-03-04  \n1             1988        Male          27  2017-03-27  \n2             1988        Male          26  2019-06-30  \n3             1969        Male          27  2018-11-16  \n4             1986        Male          26  2017-11-01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>duration</th>\n      <th>station_A_id</th>\n      <th>station_A_name</th>\n      <th>station_B_id</th>\n      <th>station_B_name</th>\n      <th>bike_id</th>\n      <th>user_type</th>\n      <th>user_birth_year</th>\n      <th>user_gender</th>\n      <th>tire_sizes</th>\n      <th>ride_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>11</td>\n      <td>16</td>\n      <td>Steuart St at Market St</td>\n      <td>93</td>\n      <td>4th St at Mission Bay Blvd S</td>\n      <td>5504</td>\n      <td>Subscriber</td>\n      <td>1988</td>\n      <td>Male</td>\n      <td>27</td>\n      <td>2018-03-04</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>8</td>\n      <td>3</td>\n      <td>Powell St BART Station (Market St at 4th St)</td>\n      <td>93</td>\n      <td>4th St at Mission Bay Blvd S</td>\n      <td>2915</td>\n      <td>Subscriber</td>\n      <td>1988</td>\n      <td>Male</td>\n      <td>27</td>\n      <td>2017-03-27</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>11</td>\n      <td>15</td>\n      <td>San Francisco Ferry Building (Harry Bridges Pl...</td>\n      <td>67</td>\n      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n      <td>5340</td>\n      <td>Customer</td>\n      <td>1988</td>\n      <td>Male</td>\n      <td>26</td>\n      <td>2019-06-30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>21</td>\n      <td>Montgomery St BART Station (Market St at 2nd St)</td>\n      <td>50</td>\n      <td>2nd St at Townsend St</td>\n      <td>746</td>\n      <td>Subscriber</td>\n      <td>1969</td>\n      <td>Male</td>\n      <td>27</td>\n      <td>2018-11-16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>11</td>\n      <td>81</td>\n      <td>Berry St at 4th St</td>\n      <td>21</td>\n      <td>Montgomery St BART Station (Market St at 2nd St)</td>\n      <td>5477</td>\n      <td>Subscriber</td>\n      <td>1986</td>\n      <td>Male</td>\n      <td>26</td>\n      <td>2017-11-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing = pd.read_csv(\"data/ride__sharing_id.csv\",index_col=0)\n",
    "ride_sharing.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find duplicated rows of <code>ride_id</code> in the <code>ride_sharing</code> DataFrame while setting <code>keep</code> to <code>False</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Find duplicates\n",
    "duplicates = ride_sharing.duplicated(subset=[\"ride_id\"], keep = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Subset <code>ride_sharing</code> on <code>duplicates</code> and sort by <code>ride_id</code> and assign the results to <code>duplicated_rides</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "\n",
    "# Sort your duplicated rides\n",
    "duplicated_rides = ride_sharing[duplicates].sort_values('ride_id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the <code>ride_id</code>, <code>duration</code> and <code>user_birth_year</code> columns of <code>duplicated_rides</code> in that order."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ride_id  duration  user_birth_year\n",
      "22       33        10             1979\n",
      "39       33         2             1979\n",
      "53       55         9             1985\n",
      "65       55         9             1985\n",
      "74       71        11             1997\n",
      "75       71        11             1997\n",
      "76       89         9             1986\n",
      "77       89         9             2060\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print relevant columns of duplicated_rides\n",
    "print(duplicated_rides[['ride_id','duration','user_birth_year']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Treating duplicates\n",
    "\n",
    "<p>In the last exercise, you were able to verify that the new update feeding into <code>ride_sharing</code> contains a bug generating both complete and incomplete duplicated rows for some values of the <code>ride_id</code> column, with occasional discrepant values for the <code>user_birth_year</code> and <code>duration</code> columns. </p>\n",
    "<p>In this exercise, you will be treating those duplicated rows by first dropping complete duplicates, and then merging the incomplete duplicate rows into one while keeping the average <code>duration</code>, and the minimum <code>user_birth_year</code> for each set of incomplete duplicate rows.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Drop complete duplicates in <code>ride_sharing</code> and store the results in <code>ride_dup</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "\n",
    "# Drop complete duplicates from ride_sharing\n",
    "ride_dup = ride_sharing.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the <code>statistics</code> dictionary which holds <strong>min</strong>imum aggregation for <code>user_birth_year</code> and <strong>mean</strong> aggregation for <code>duration</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "\n",
    "# Create statistics dictionary for aggregation function\n",
    "statistics = {'user_birth_year': \"min\", 'duration': \"mean\"}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop incomplete duplicates by grouping by <code>ride_id</code> and applying the aggregation in <code>statistics</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "\n",
    "# Group by ride_id and compute new statistics\n",
    "ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find duplicates again and run the <code>assert</code> statement to verify de-duplication."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "\n",
    "# Find duplicated values again\n",
    "duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
    "duplicated_rides = ride_unique[duplicates == True]\n",
    "\n",
    "# Assert duplicates are processed\n",
    "assert duplicated_rides.shape[0] == 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# Text and categorical data problems"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Finding consistency\n",
    "\n",
    "<p>In this exercise and throughout this chapter, you'll be working with the <code>airlines</code> DataFrame which contains survey responses on the San Francisco Airport from airline customers.</p>\n",
    "<p>The DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction. Another DataFrame named <code>categories</code> was created, containing all correct possible values for the survey columns. </p>\n",
    "<p>In this exercise, you will use both of these DataFrames to find survey answers with inconsistent values, and drop them, effectively performing an outer and inner join on both these DataFrames as seen in the video exercise. The <code>pandas</code> package has been imported as <code>pd</code>, and the <code>airlines</code> and <code>categories</code> DataFrames are in your environment.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "categories = pd.read_csv(\"data/categories.csv\",index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "(2477, 12)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines = pd.read_csv(\"data/airlines_final.csv\",index_col=0)\n",
    "airlines.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Print the <code>categories</code> DataFrame and take a close look at all possible correct categories of the survey columns."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cleanliness           safety          satisfaction\n",
      "0           Clean          Neutral        Very satisfied\n",
      "1         Average        Very safe               Neutral\n",
      "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
      "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
      "4           Dirty  Somewhat unsafe      Very unsatisfied\n"
     ]
    }
   ],
   "source": [
    "print(categories)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Print the unique values of the survey columns in <code>airlines</code> using the <code>.unique()</code> method."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanliness:  ['Clean' 'Average' 'Unacceptable' 'Somewhat clean' 'Somewhat dirty'\n",
      " 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satisfied' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines[\"safety\"].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines[\"satisfaction\"].unique(), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "cleanliness , it has an Unacceptable category."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id        day           airline  destination  dest_region dest_size  \\\n",
      "4    2992  Wednesday          AMERICAN        MIAMI      East US       Hub   \n",
      "18   2913     Friday  TURKISH AIRLINES     ISTANBUL  Middle East       Hub   \n",
      "100  2321  Wednesday         SOUTHWEST  LOS ANGELES      West US       Hub   \n",
      "\n",
      "    boarding_area   dept_time  wait_min   cleanliness         safety  \\\n",
      "4     Gates 50-59  2018-12-31     559.0  Unacceptable      Very safe   \n",
      "18   Gates 91-102  2018-12-31     225.0  Unacceptable      Very safe   \n",
      "100   Gates 20-39  2018-12-31     130.0  Unacceptable  Somewhat safe   \n",
      "\n",
      "           satisfaction  \n",
      "4    Somewhat satisfied  \n",
      "18   Somewhat satisfied  \n",
      "100  Somewhat satisfied  \n"
     ]
    }
   ],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines[\"cleanliness\"].unique()).difference(set(categories[\"cleanliness\"]))\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id       day        airline        destination    dest_region  \\\n",
      "0     1351   Tuesday    UNITED INTL             KANSAI           Asia   \n",
      "1      373    Friday         ALASKA  SAN JOSE DEL CABO  Canada/Mexico   \n",
      "2     2820  Thursday          DELTA        LOS ANGELES        West US   \n",
      "3     1157   Tuesday      SOUTHWEST        LOS ANGELES        West US   \n",
      "5      634  Thursday         ALASKA             NEWARK        East US   \n",
      "...    ...       ...            ...                ...            ...   \n",
      "2804  1475   Tuesday         ALASKA       NEW YORK-JFK        East US   \n",
      "2805  2222  Thursday      SOUTHWEST            PHOENIX        West US   \n",
      "2806  2684    Friday         UNITED            ORLANDO        East US   \n",
      "2807  2549   Tuesday        JETBLUE         LONG BEACH        West US   \n",
      "2808  2162  Saturday  CHINA EASTERN            QINGDAO           Asia   \n",
      "\n",
      "     dest_size boarding_area   dept_time  wait_min     cleanliness  \\\n",
      "0          Hub  Gates 91-102  2018-12-31     115.0           Clean   \n",
      "1        Small   Gates 50-59  2018-12-31     135.0           Clean   \n",
      "2          Hub   Gates 40-48  2018-12-31      70.0         Average   \n",
      "3          Hub   Gates 20-39  2018-12-31     190.0           Clean   \n",
      "5          Hub   Gates 50-59  2018-12-31     140.0  Somewhat clean   \n",
      "...        ...           ...         ...       ...             ...   \n",
      "2804       Hub   Gates 50-59  2018-12-31     280.0  Somewhat clean   \n",
      "2805       Hub   Gates 20-39  2018-12-31     165.0           Clean   \n",
      "2806       Hub   Gates 70-90  2018-12-31      92.0           Clean   \n",
      "2807     Small    Gates 1-12  2018-12-31      95.0           Clean   \n",
      "2808     Large    Gates 1-12  2018-12-31     220.0           Clean   \n",
      "\n",
      "             safety        satisfaction  \n",
      "0           Neutral      Very satisfied  \n",
      "1         Very safe      Very satisfied  \n",
      "2     Somewhat safe             Neutral  \n",
      "3         Very safe  Somewhat satisfied  \n",
      "5         Very safe      Very satisfied  \n",
      "...             ...                 ...  \n",
      "2804        Neutral  Somewhat satisfied  \n",
      "2805      Very safe      Very satisfied  \n",
      "2806      Very safe      Very satisfied  \n",
      "2807  Somewhat safe      Very satisfied  \n",
      "2808      Very safe  Somewhat satisfied  \n",
      "\n",
      "[2474 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print rows with consistent categories only\n",
    "print(airlines[~cat_clean_rows])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Categorical variables"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Categorical variables\n",
    "\n",
    "Awesome work on the last lesson. Now let's discuss other types of problems that could affect categorical variables."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. What type of errors could we have?\n",
    "\n",
    "In the last lesson, we saw how categorical data has a value membership constraint, where columns need to have a predefined set of values. However, this is not the only set of problems we may encounter. When cleaning categorical data, some of the problems we may encounter include value inconsistency, the presence of too many categories that could be collapsed into one, and making sure data is of the right type."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Value consistency\n",
    "\n",
    "Let's start with making sure our categorical data is consistent. A common categorical data problem is having values that slightly differ because of capitalization. Not treating this could lead to misleading results when we decide to analyze our data, for example, let's assume we're working with a demographics dataset, and we have a marriage status column with inconsistent capitalization. Here's what counting the number of married people in the marriage_status Series would look like. Note that the dot-value_counts() methods works on Series only."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Value consistency\n",
    "\n",
    "For a DataFrame, we can groupby the column and use the dot-count() method."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. Value consistency\n",
    "\n",
    "To deal with this, we can either capitalize or lowercase the marriage_status column. This can be done with the str-dot-upper() or dot-lower() functions respectively."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. Value consistency\n",
    "\n",
    "Another common problem with categorical values are leading or trailing spaces. For example, imagine the same demographics DataFrame containing values with leading spaces. Here's what the counts of married vs unmarried people would look like. Note that there is a married category with a trailing space on the right, which makes it hard to spot on the output, as opposed to unmarried."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. Value consistency\n",
    "\n",
    "To remove leading spaces, we can use the str-dot-strip() method which when given no input, strips all leading and trailing white spaces."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. Collapsing data into categories\n",
    "\n",
    "Sometimes, we may want to create categories out of our data, such as creating household income groups from income data. To create categories out of data, let's use the example of creating an income group column in the demographics DataFrame. We can do this in 2 ways. The first method utilizes the qcut function from pandas, which automatically divides our data based on its distribution into the number of categories we set in the q argument, we created the category names in the group_names list and fed it to the labels argument, returning the following. Notice that the first row actually misrepresents the actual income of the income group, as we didn't instruct qcut where our ranges actually lie."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. Collapsing data into categories\n",
    "\n",
    "We can do this with the cut function instead, which lets us define category cutoff ranges with the bins argument. It takes in a list of cutoff points for each category, with the final one being infinity represented with np-dot-inf(). From the output, we can see this is much more correct."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. Collapsing data into categories\n",
    "\n",
    "Sometimes, we may want to reduce the amount of categories we have in our data. Let's move on to mapping categories to fewer ones. For example, assume we have a column containing the operating system of different devices, and contains these unique values. Say we want to collapse these categories into 2, DesktopOS, and MobileOS. We can do this using the replace method. It takes in a dictionary that maps each existing category to the category name you desire. In this case, this is the mapping dictionary. A quick print of the unique values of operating system shows the mapping has been complete."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 11. Let's practice!\n",
    "\n",
    "Now that we know about treating categorical data, let's practice!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Inconsistent categories\n",
    "\n",
    "<p>In this exercise, you'll be revisiting the <code>airlines</code> DataFrame from the previous lesson.</p>\n",
    "<p>As a reminder, the DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction on the San Francisco Airport.</p>\n",
    "<p>In this exercise, you will examine two categorical columns from this DataFrame, <code>dest_region</code> and <code>dest_size</code> respectively, assess how to address them and make sure that they are cleaned and ready for analysis. The <code>pandas</code> package has been imported as <code>pd</code>, and the <code>airlines</code> DataFrame is in your environment.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Print the unique values in <code>dest_region</code> and <code>dest_size</code> respectively."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "print(airlines[\"dest_region\"].unique())\n",
    "print(airlines[\"dest_size\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. The dest_region column has inconsistent values due to capitalization and has one value that needs to be remapped\n",
    "\n",
    "2. The dest_size column has only inconsistent values due to leading and trailing spaces.\n",
    "3."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines[\"dest_region\"] = airlines[\"dest_region\"].str.lower()\n",
    "airlines[\"dest_region\"] = airlines[\"dest_region\"].replace({\"eur\":\"europe\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Remove white spaces from `dest_size`\n",
    "airlines[\"dest_size\"] = airlines[\"dest_size\"].str.strip()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "# Verify changes have been effected\n",
    "print(airlines[\"dest_region\"].unique())\n",
    "print(airlines[\"dest_size\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Remapping categories\n",
    "\n",
    "<p>To better understand survey respondents from <code>airlines</code>, you want to find out if there is a relationship between certain responses and the day of the week and wait time at the gate.</p>\n",
    "<p>The <code>airlines</code> DataFrame contains the <code>day</code> and <code>wait_min</code> columns, which are categorical and numerical respectively. The <code>day</code> column contains the exact day a flight took place, and <code>wait_min</code> contains the amount of minutes it took travelers to wait at the gate. To make your analysis easier, you want to create two new categorical variables:</p>\n",
    "<ul>\n",
    "<li><code>wait_type</code>: <code>'short'</code> for 0-60 min, <code>'medium'</code> for 60-180 and <code>long</code> for 180+</li>\n",
    "<li><code>day_week</code>: <code>'weekday'</code> if day is in the weekday, <code>'weekend'</code> if day is in the weekend.</li>\n",
    "</ul>\n",
    "<p>The <code>pandas</code> and <code>numpy</code> packages have been imported as <code>pd</code> and <code>np</code>. Let's create some new categorical data!</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Create the ranges and labels for the <code>wait_type</code> column mentioned in the description."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Create the <code>wait_type</code> column by from <code>wait_min</code> by using <code>pd.cut()</code>, while inputting <code>label_ranges</code> and <code>label_names</code> in the correct arguments."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Create the <code>mapping</code> dictionary mapping weekdays to <code>'weekday'</code> and weekend days to <code>'weekend'</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Create the <code>day_week</code> column by using <code>.replace()</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "0    115.0\n1    135.0\n2     70.0\n3    190.0\n4    559.0\nName: wait_min, dtype: float64"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines[\"wait_min\"].head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "0         Tuesday\n1          Friday\n2        Thursday\n3         Tuesday\n4       Wednesday\n          ...    \n2804      Tuesday\n2805     Thursday\n2806       Friday\n2807      Tuesday\n2808     Saturday\nName: day, Length: 2477, dtype: object"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines[\"day\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "#Collasping the columns into category\n",
    "label_ranges = [0,60,180,np.inf]\n",
    "label_names = [\"short\",\"medium\",\"long\"]\n",
    "airlines[\"wait_type\"] =  pd.cut(x=airlines[\"wait_min\"],bins=label_ranges,\n",
    "                                labels=label_names)\n",
    "weekend = [\"Saturday\",\"Sunday\"]\n",
    "condition = lambda x : \"weekend\" if x in weekend else \"weekday\"\n",
    "airlines[\"day_week\"] = airlines[\"day\"].map(condition)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Cleaning text data"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Cleaning text data\n",
    "\n",
    "Good job on the previous lesson. In the final lesson of this chapter, we'll talk about text data and regular expressions."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. What is text data?\n",
    "\n",
    "Text data is one of the most common types of data types. Examples of it range from names, phone numbers, addresses, emails and more. Common text data problems include handling inconsistencies, making sure text data is of a certain length, typos and others."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Example\n",
    "\n",
    "Let's take a look at the following example. Here's a DataFrame named phones containing the full name and phone numbers of individuals. Both are string columns. Notice the phone number column."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Example\n",
    "\n",
    "We can see that there are phone number values, that begin with 00 or +. We also see that there is one entry where the phone number is 4 digits, which is non-existent. Furthermore, we can see that there are dashes across the phone number column. If we wanted to feed these phone numbers into an automated call system, or create a report discussing the distribution of users by area code, we couldn't really do so without uniform phone numbers."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. Example\n",
    "\n",
    "Ideally, we'd want to the phone number column as such. Where all phone numbers are aligned to begin with 00, where any number below the 10 digit value is replaced with NaN to represent a missing value, and where all dashes have been removed. Let's see how that's done!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. Fixing the phone number column\n",
    "\n",
    "Let's first begin by replacing the plus sign with 00, to do this, we use the dot str dot replace method which takes in two values, the string being replaced, which is in this case the plus sign and the string to replace it with which is in this case 00. We can see that the column has been updated."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. Fixing the phone number column\n",
    "\n",
    "We use the same exact technique to remove the dashes, by replacing the dash symbol with an empty string."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. Fixing the phone number column\n",
    "\n",
    "Now finally we're going to replace all phone numbers below 10 digits to NaN. We can do this by chaining the Phone number column with the dot str dot len method, which returns the string length of each row in the column. We can then use the dot loc method, to index rows where digits is below 10, and replace the value of Phone number with numpy's nan object, which is here imported as np."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. Fixing the phone number column\n",
    "\n",
    "We can also write assert statements to test whether the phone number column has a specific length,and whether it contains the symbols we removed. The first assert statement tests that the minimum length of the strings in the phone number column, found through str dot len, is bigger than or equal to 10. In the second assert statement, we use the str dot contains method to test whether the phone number column contains a specific pattern. It returns a series of booleans for that are True for matches and False for non-matches. We set the pattern plus bar pipe minus, the bar pipe here is basically an or statement, so we're trying to find matches for either symbols. We chain it with the any method which returns True if any element in the output of our dot-str-contains is True, and test whether the it returns False."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. But what about more complicated examples?\n",
    "\n",
    "But what about more complicated examples? How can we clean a phone number column that looks like this for example? Where phone numbers can contain a range of symbols from plus signs, dashes, parenthesis and maybe more. This is where regular expressions come in. Regular expressions give us the ability to search for any pattern in text data, like only digits for example. They are like control + find in your browser, but way more dynamic and robust."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 11. Regular expressions in action\n",
    "\n",
    "Let's a look at this example. Here we are attempting to only extract digits from the phone number column. To do this, we use the dot str dot replace method with the pattern we want to replace with an empty string. Notice the pattern fed into the method. This is essentially us telling pandas to replace anything that is not a digit with nothing. We won't get into the specifics of regular expressions, and how to construct them, but they are immensely useful for difficult string cleaning tasks, so make sure to check out DataCamp's course library on regular expressions."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 12. Let's practice!\n",
    "\n",
    "Now that we know how to clean text data, let's get to practice!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Removing titles and taking names\n",
    "\n",
    "<p>While collecting survey respondent metadata in the <code>airlines</code> DataFrame, the full name of respondents was saved in the <code>full_name</code> column. However upon closer inspection, you found that a lot of the different names are prefixed by honorifics such as <code>\"Dr.\"</code>, <code>\"Mr.\"</code>, <code>\"Ms.\"</code> and <code>\"Miss\"</code>. </p>\n",
    "<p>Your ultimate objective is to create two new columns named <code>first_name</code> and <code>last_name</code>, containing the first and last names of respondents respectively. Before doing so however, you need to remove honorifics.</p>\n",
    "<p>The <code>airlines</code> DataFrame is in your environment, alongside <code>pandas</code> as <code>pd.</code></p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "     id                full_name        day      airline        destination  \\\n0  1351           Melodie Stuart    Tuesday  UNITED INTL             KANSAI   \n1   373          Dominic Shannon     Friday       ALASKA  SAN JOSE DEL CABO   \n2  2820        Quintessa Tillman   Thursday        DELTA        LOS ANGELES   \n3  1157  Dr. Christine Nicholson    Tuesday    SOUTHWEST        LOS ANGELES   \n4  2992          Regina Clements  Wednesday     AMERICAN              MIAMI   \n\n     dest_region dest_size boarding_area   dept_time  wait_min  \\\n0           Asia       Hub  Gates 91-102  2018-12-31     115.0   \n1  Canada/Mexico     Small   Gates 50-59  2018-12-31     135.0   \n2        West US       Hub   Gates 40-48  2018-12-31      70.0   \n3        West US       Hub   Gates 20-39  2018-12-31     190.0   \n4        East US       Hub   Gates 50-59  2018-12-31     559.0   \n\n      cleanliness         safety        satisfaction  \n0           Clean        Neutral      Very satisfied  \n1           Clean      Very safe      Very satisfied  \n2         Average  Somewhat safe             Neutral  \n3           Clean      Very safe  Somewhat satsified  \n4  Somewhat clean      Very safe  Somewhat satsified  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>full_name</th>\n      <th>day</th>\n      <th>airline</th>\n      <th>destination</th>\n      <th>dest_region</th>\n      <th>dest_size</th>\n      <th>boarding_area</th>\n      <th>dept_time</th>\n      <th>wait_min</th>\n      <th>cleanliness</th>\n      <th>safety</th>\n      <th>satisfaction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1351</td>\n      <td>Melodie Stuart</td>\n      <td>Tuesday</td>\n      <td>UNITED INTL</td>\n      <td>KANSAI</td>\n      <td>Asia</td>\n      <td>Hub</td>\n      <td>Gates 91-102</td>\n      <td>2018-12-31</td>\n      <td>115.0</td>\n      <td>Clean</td>\n      <td>Neutral</td>\n      <td>Very satisfied</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>373</td>\n      <td>Dominic Shannon</td>\n      <td>Friday</td>\n      <td>ALASKA</td>\n      <td>SAN JOSE DEL CABO</td>\n      <td>Canada/Mexico</td>\n      <td>Small</td>\n      <td>Gates 50-59</td>\n      <td>2018-12-31</td>\n      <td>135.0</td>\n      <td>Clean</td>\n      <td>Very safe</td>\n      <td>Very satisfied</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2820</td>\n      <td>Quintessa Tillman</td>\n      <td>Thursday</td>\n      <td>DELTA</td>\n      <td>LOS ANGELES</td>\n      <td>West US</td>\n      <td>Hub</td>\n      <td>Gates 40-48</td>\n      <td>2018-12-31</td>\n      <td>70.0</td>\n      <td>Average</td>\n      <td>Somewhat safe</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1157</td>\n      <td>Dr. Christine Nicholson</td>\n      <td>Tuesday</td>\n      <td>SOUTHWEST</td>\n      <td>LOS ANGELES</td>\n      <td>West US</td>\n      <td>Hub</td>\n      <td>Gates 20-39</td>\n      <td>2018-12-31</td>\n      <td>190.0</td>\n      <td>Clean</td>\n      <td>Very safe</td>\n      <td>Somewhat satsified</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2992</td>\n      <td>Regina Clements</td>\n      <td>Wednesday</td>\n      <td>AMERICAN</td>\n      <td>MIAMI</td>\n      <td>East US</td>\n      <td>Hub</td>\n      <td>Gates 50-59</td>\n      <td>2018-12-31</td>\n      <td>559.0</td>\n      <td>Somewhat clean</td>\n      <td>Very safe</td>\n      <td>Somewhat satsified</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines = pd.read_csv(\"data/air_lines_with_name.csv\",index_col=0)\n",
    "airlines.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "0             Melodie Stuart\n1            Dominic Shannon\n2          Quintessa Tillman\n3    Dr. Christine Nicholson\n4            Regina Clements\nName: full_name, dtype: object"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines[\"full_name\"].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Remove <code>\"Dr.\"</code>, <code>\"Mr.\"</code>, <code>\"Miss\"</code> and <code>\"Ms.\"</code> from <code>full_name</code> by replacing them with an empty string <code>\"\"</code> in that order."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\",regex =False)\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\",regex =False)\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\",\"\",regex =False)\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\",regex =False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the <code>assert</code> statement using <code>.str.contains()</code> that tests whether <code>full_name</code> still contains any of the honorifics."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Keeping it descriptive\n",
    "\n",
    "<p>To further understand travelers' experiences in the San Francisco Airport, the quality assurance department sent out a qualitative questionnaire to all travelers who gave the airport the worst score on all possible categories. The objective behind this questionnaire is to identify common patterns in what travelers are saying about the airport. </p>\n",
    "<p>Their response is stored in the <code>survey_response</code> column. Upon a closer look, you realized a few of the answers gave the shortest possible character amount without much substance. In this exercise, you will isolate the responses with a character count higher than <strong><em>40</em></strong> , and make sure your new DataFrame contains responses with <strong><em>40</em></strong> characters or more using an <code>assert</code> statement. </p>\n",
    "<p>The <code>airlines</code> DataFrame is in your environment, and <code>pandas</code> is imported as <code>pd</code>.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "0                                       It was terrible\n1                             I didn\\'t like the flight\n2                                          I hate this \n3                                             Not a fan\n4                                                   Bad\n5                                              Horrible\n6                                             Very poor\n8                                   Unacceptable flight\n9                                          It was awful\n10                     My fllight was really unpleasant\n11                                       I am not a fan\n12                                   I had a bad flight\n13                                      It was very bad\n14                                      it was horrible\n15                                             Terrible\n16                                   It was substandard\n17                           I did not enjoy the flight\n18    The airport personnell forgot to alert us of d...\n19    The food in the airport was really really expe...\n20    One of the other travelers was really loud and...\n21    I don\\'t remember answering the survey with th...\n22    The airport personnel kept ignoring my request...\n23    The chair I sat in was extremely uncomfortable...\n24    I wish you were more like other airports, the ...\n25    I was really unsatisfied with the wait times b...\n27    The flight was okay, but I didn\\'t really like...\n28    We were really slowed down by security measure...\n29    There was a spill on the aisle next to the bat...\n30    I felt very unsatisfied by how long the flight...\nName: survey_response, dtype: object"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines = pd.read_csv(\"data/airlines_survey.csv\",index_col=0)\n",
    "airlines[\"survey_response\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Using the <code>airlines</code> DataFrame, store the length of each instance in the <code>survey_response</code> column in <code>resp_length</code> by using <code>.str.len()</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "resp_length = airlines[\"survey_response\"].str.len()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Isolate the rows of <code>airlines</code> with <code>resp_length</code> higher than <code>40</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "airlines_survey = airlines[resp_length > 40]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Assert that the smallest <code>survey_response</code> length in <code>airlines_survey</code> is now bigger than <code>40</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "assert airlines_survey[\"survey_response\"].str.len().min() > 40"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# Advanced data problems"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Uniformity"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Uniformity\n",
    "\n",
    "Stellar work on chapter 2! You're now an expert at handling categorical and text variables."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. In this chapter\n",
    "\n",
    "In this chapter, we're looking at more advanced data cleaning problems, such as uniformity, cross field validation and dealing with missing data."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Data range constraints\n",
    "\n",
    "In chapter 1, we saw how out of range values are a common problem when cleaning data, and that when left untouched, can skew your analysis."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Uniformity\n",
    "\n",
    "In this lesson, we're going to tackle a problem that could similarly skew our data, which is unit uniformity. For example, we can have temperature data that has values in both Fahrenheit and Celsius, weight data in Kilograms and in stones, dates in multiple formats, and so on. Verifying unit uniformity is imperative to having accurate analysis."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. An example\n",
    "\n",
    "Here's a dataset with average temperature data throughout the month of March in New York City. The dataset was collected from different sources with temperature data in Celsius and Fahrenheit merged together. We can see that unless a major climate event occurred,"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. An example\n",
    "\n",
    "this value here is most likely Fahrenheit, not Celsius. Let's confirm the presence of these values visually."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. An example\n",
    "\n",
    "We can do so by plotting a scatter plot of our data. We can do this using matplotlib.pyplot, which was imported as plt. We use the plt dot scatter function, which takes in what to plot on the x axis, the y axis, and which data source to use. We set the title, axis labels with the helper functions seen here, show the plot with plt dot show,"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. Insert title here...\n",
    "\n",
    "and voila."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. Insert title here...\n",
    "\n",
    "Notice these values here? They all must be fahrenheit."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. Treating temperature data\n",
    "\n",
    "A simple web search returns the formula for converting Fahrenheit to Celsius. To convert our temperature data, we isolate all rows of temperature column where it is above 40 using the loc method. We chose 40 because it's a common sense maximum for Celsius temperatures in New York City. We then convert these values to Celsius using the formula above, and reassign them to their respective Fahrenheit values in temperatures. We can make sure that our conversion was correct with an assert statement, by making sure the maximum value of temperature is less than 40."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 11. Treating date data\n",
    "\n",
    "Here's another common uniformity problem with date data. This is a DataFrame called birthdays containing birth dates for a variety of individuals. It has been collected from a variety of sources and merged into one."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 12. Treating date data\n",
    "\n",
    "Notice the dates here? The one in blue has the month, day, year format, whereas the one in orange has the month written out. The one in red is obviously an error, with what looks like a day day year format. We'll learn how to deal with that one as well."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 13. Datetime formatting\n",
    "\n",
    "We already discussed datetime objects. Without getting too much into detail, datetime accepts different formats that help you format your dates as pleased. The pandas to datetime function automatically accepts most date formats, but could raise errors when certain formats are unrecognizable. You don't have to memorize these formats, just know that they exist and are easily searchable!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 14. Treating date data\n",
    "\n",
    "You can treat these date inconsistencies easily by converting your date column to datetime. We can do this in pandas with the to_datetime function. However this isn't enough and will most likely return an error, since we have dates in multiple formats, especially the weird day/day/format which triggers an error with months. Instead we set the infer_datetime_format argument to True, and set errors equal to coerce. This will infer the format and return missing value for dates that couldn't be identified and converted instead of a value error."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 15. Treating date data\n",
    "\n",
    "This returns the birthday column with aligned formats, with the initial ambiguous format of day day year, being set to NAT, which represents missing values in Pandas for datetime objects."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 16. Treating date data\n",
    "\n",
    "We can also convert the format of a datetime column using the dt dot strftime method, which accepts a datetime format of your choice. For example, here we convert the Birthday column to day month year, instead of year month day."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 17. Treating ambiguous date data\n",
    "\n",
    "However a common problem is having ambiguous dates with vague formats. For example, is this date value set in March or August? Unfortunately there's no clear cut way to spot this inconsistency or to treat it. Depending on the size of the dataset and suspected ambiguities, we can either convert these dates to NAs and deal with them accordingly. If you have additional context on the source of your data, you can probably infer the format. If the majority of subsequent or previous data is of one format, you can probably infer the format as well. All in all, it is essential to properly understand where your data comes from, before trying to treat it, as it will make making these decisions much easier."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 18. Let's practice!\n",
    "\n",
    "Now let's make our data uniform!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Uniform currencies\n",
    "\n",
    "<p>In this exercise and throughout this chapter, you will be working with a retail banking dataset stored in the <code>banking</code> DataFrame. \n",
    "The dataset contains data on the amount of money stored in accounts (<code>acct_amount</code>), their currency (<code>acct_cur</code>), amount invested (<code>inv_amount</code>), account opening date (<code>account_opened</code>), and last transaction date (<code>last_transaction</code>) that were consolidated from American and European branches. </p>\n",
    "<p>You are tasked with understanding the average account size and how investments vary by the size of account, however in order to produce this analysis accurately, you first need to unify the currency amount into dollars. The <code>pandas</code> package has been imported as <code>pd</code>, and the <code>banking</code> DataFrame is in your environment.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "    cust_id  acct_amount acct_cur  inv_amount account_opened last_transaction\n0  8C35540A     44244.71   dollar    35500.50       03-05-18         30-09-19\n1  D5536652     86506.85   dollar    81921.86       21-01-18         14-01-19\n2  A631984D     77799.33   dollar    46412.27       26-01-18         06-10-19\n3  93F2F951     93875.24     euro    76563.35       21-08-17         10-07-19\n4  DE0A0882     99998.35     euro    18669.01       05-06-17         15-01-19",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cust_id</th>\n      <th>acct_amount</th>\n      <th>acct_cur</th>\n      <th>inv_amount</th>\n      <th>account_opened</th>\n      <th>last_transaction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8C35540A</td>\n      <td>44244.71</td>\n      <td>dollar</td>\n      <td>35500.50</td>\n      <td>03-05-18</td>\n      <td>30-09-19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D5536652</td>\n      <td>86506.85</td>\n      <td>dollar</td>\n      <td>81921.86</td>\n      <td>21-01-18</td>\n      <td>14-01-19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A631984D</td>\n      <td>77799.33</td>\n      <td>dollar</td>\n      <td>46412.27</td>\n      <td>26-01-18</td>\n      <td>06-10-19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>93F2F951</td>\n      <td>93875.24</td>\n      <td>euro</td>\n      <td>76563.35</td>\n      <td>21-08-17</td>\n      <td>10-07-19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DE0A0882</td>\n      <td>99998.35</td>\n      <td>euro</td>\n      <td>18669.01</td>\n      <td>05-06-17</td>\n      <td>15-01-19</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking = pd.read_csv(\"data/banking_cur.csv\",index_col=0)\n",
    "banking.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['cust_id', 'acct_amount', 'acct_cur', 'inv_amount', 'account_opened',\n       'last_transaction'],\n      dtype='object')"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking.columns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Find the rows of <code>acct_cur</code> in <code>banking</code> that are equal to <code>'euro'</code> and store them in the variable <code>acct_eu</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# Find values of acct_cur that are equal to 'euro'\n",
    "acct_eu = banking['acct_cur'] == 'euro'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find all the rows of <code>acct_amount</code> in <code>banking</code> that fit the <code>acct_eu</code> condition, and convert them to USD by multiplying them with <code>1.1</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "\n",
    "# Convert acct_amount where it is in euro to dollars\n",
    "banking.loc[acct_eu, 'acct_amount'] = banking.loc[acct_eu, 'acct_amount'] * 1.1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find all the rows of <code>acct_cur</code> in <code>banking</code> that fit the <code>acct_eu</code> condition, set them to <code>'dollar'</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "\n",
    "# Unify acct_cur column by changing 'euro' values to 'dollar'\n",
    "banking.loc[acct_eu, 'acct_cur'] = 'dollar'\n",
    "\n",
    "# Assert that only dollar currency remains\n",
    "assert banking['acct_cur'].unique() == 'dollar'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Uniform dates\n",
    "\n",
    "<p>After having unified the currencies of your different account amounts, you want to add a temporal dimension to your analysis and see how customers have been investing their money given the size of their account over each year. \n",
    "The <code>account_opened</code> column represents when customers opened their accounts and is a good proxy for segmenting customer activity and investment over time. </p>\n",
    "<p>However, since this data was consolidated from multiple sources, you need to make sure that all dates are of the same format. You will do so by converting this column into a <code>datetime</code> object, while making sure that the format is inferred and potentially incorrect formats are set to missing. The <code>banking</code> DataFrame is in your environment and <code>pandas</code> was imported as <code>pd</code>.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "banking = pd.read_csv(\"data/banking_data.csv\",index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Print the header of <code>account_opened</code> from the <code>banking</code> DataFrame and take a look at the different results."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          2018-03-05\n",
      "1            21-01-18\n",
      "2    January 26, 2018\n",
      "3            21-14-17\n",
      "4            05-06-17\n",
      "Name: account_opened, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(banking[\"account_opened\"].head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# Convert account_opened to datetime\n",
    "banking['account_opened'] = pd.to_datetime(banking[\"account_opened\"],\n",
    "                                           # Infer datetime format\n",
    "                                           infer_datetime_format = True,\n",
    "                                           # Return missing value for error\n",
    "                                           errors = \"coerce\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "0     2018\n1     2018\n2     2018\n3      NaN\n4     2017\n      ... \n92    2017\n93    2018\n94    2018\n95    2017\n96    2017\nName: acct_year, Length: 97, dtype: object"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get year of account opened\n",
    "banking['acct_year'] = banking['account_opened'].dt.strftime(\"%Y\")\n",
    "# Print acct_year\n",
    "banking[\"acct_year\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Cross field validation"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Cross field validation\n",
    "\n",
    "Hi and welcome to the second lesson of this chapter! In this lesson we'll talk about cross field validation for diagnosing dirty data."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. Motivation\n",
    "\n",
    "Let's take a look at the following dataset. It contains flight statistics on the total number of passengers in economy, business and first class as well as the total passengers for each flight. We know that these columns have been collected and merged from different data sources, and a common challenge when merging data from different sources is data integrity, or more broadly making sure that our data is correct."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Cross field validation\n",
    "\n",
    "This is where cross field validation comes in. Cross field validation is the use of multiple fields in your dataset to sanity check the integrity of your data. For example in our flights dataset, this could be summing economy, business and first class values and making sure they are equal to the total passengers on the plane. This could be easily done in Pandas, by first subsetting on the columns to sum, then using the sum method with the axis argument set to 1 to indicate row wise summing. We then find instances where the total passengers column is equal to the sum of the classes. And find and filter out instances of inconsistent passenger amounts by subsetting on the equality we created with brackets and the tilde symbol."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Cross field validation\n",
    "\n",
    "Here's another example containing user IDs, birthdays and age values for a set of users. We can for example make sure that the age and birthday columns are correct by subtracting the number of years between today's date and each birthday."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. Cross field validation\n",
    "\n",
    "We can do this by first making sure the Birthday column is converted to datetime with the pandas to datetime function. We then create an object storing today's date using the datetime package's date dot today function. We then calculate the difference in years between today's date's year, and the year of each birthday by using the dot dt dot year attribute of the user's Birthday column. We then find instances where the calculated ages are equal to the actual age column in the users DataFrame. We then find and filter out the instances where we have inconsistencies using subsetting with brackets and the tilde symbol on the equality we created."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. What to do when we catch inconsistencies?\n",
    "\n",
    "So what should be the course of action in case we spot inconsistencies with cross-field validation? Just like other data cleaning problems, there is no one size fits all solution, as often the best solution requires an in depth understanding of our dataset. We can decide to either drop inconsistent data, set it to missing and impute it, or apply some rules due to domain knowledge. All these routes and assumptions can be decided upon only when you have a good understanding of where your dataset comes from and the different sources feeding into it."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. Let's practice!\n",
    "\n",
    "Now that you know about cross field validation, let's get to practice!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## How's our data integrity?\n",
    "\n",
    "<p>New data has been merged into the <code>banking</code> DataFrame that contains details on how investments in the <code>inv_amount</code> column are allocated across four different funds A, B, C and D. </p>\n",
    "<p>Furthermore, the age and birthdays of customers are now stored in the <code>age</code> and <code>birth_date</code> columns respectively.</p>\n",
    "<p>You want to understand how customers of different age groups invest. However, you want to first make sure the data you're analyzing is correct. You will do so by cross field checking values of <code>inv_amount</code> and <code>age</code> against the amount invested in different funds and customers' birthdays.\n",
    "Both <code>pandas</code> and <code>datetime</code> have been imported as <code>pd</code> and <code>dt</code> respectively.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "banking = pd.read_csv(\"data/banking_fund.csv\",index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['cust_id', 'birth_date', 'age', 'acct_amount', 'inv_amount', 'fund_A',\n       'fund_B', 'fund_C', 'fund_D', 'account_opened', 'last_transaction'],\n      dtype='object')"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking.columns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Find the rows where the sum of all rows of the <code>fund_columns</code> in <code>banking</code> are equal to the <code>inv_amount</code> column."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# Store fund columns to sum against\n",
    "fund_columns = ['fund_A', 'fund_B', 'fund_C', 'fund_D']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "\n",
    "# Find rows where fund_columns row sum == inv_amount\n",
    "inv_equ = banking[fund_columns].sum(axis=1) == banking[\"inv_amount\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Store the values of <code>banking</code> with consistent <code>inv_amount</code> in <code>consistent_inv</code>, and those with inconsistent ones in <code>inconsistent_inv</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_inv = banking[inv_equ]\n",
    "inconsistent_inv = banking[~inv_equ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent investments:  8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent investments: \", inconsistent_inv.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Store today's date into <code>today</code>, and manually calculate customers' ages and store them in <code>ages_manual</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "today = dt.datetime.today()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find all rows of <code>banking</code> where the <code>age</code> column is equal to <code>ages_manual</code> and then filter <code>banking</code> into <code>consistent_ages</code> and <code>inconsistent_ages</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "0     1962\n1     1962\n2     1990\n3     1985\n4     1990\n      ... \n95    1974\n96    1989\n97    1984\n98    1969\n99    1993\nName: birth_date, Length: 100, dtype: int64"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(banking[\"birth_date\"]).dt.year"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "2022"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store today's date and find ages\n",
    "today = dt.datetime.today()\n",
    "today.year"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [119]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mbanking\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbirth_date\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdt\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   5569\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[0;32m   5570\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[0;32m   5571\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[0;32m   5572\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[0;32m   5573\u001B[0m ):\n\u001B[0;32m   5574\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[1;32m-> 5575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001B[0m, in \u001B[0;36mCachedAccessor.__get__\u001B[1;34m(self, obj, cls)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001B[39;00m\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessor\n\u001B[1;32m--> 182\u001B[0m accessor_obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_accessor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001B[39;00m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001B[39;00m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001B[39;00m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;66;03m# NDFrame\u001B[39;00m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name, accessor_obj)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:509\u001B[0m, in \u001B[0;36mCombinedDatetimelikeProperties.__new__\u001B[1;34m(cls, data)\u001B[0m\n\u001B[0;32m    506\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_period_dtype(data\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[0;32m    507\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m PeriodProperties(data, orig)\n\u001B[1;32m--> 509\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan only use .dt accessor with datetimelike values\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "banking['birth_date'].dt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent ages:  4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ages_manual = today.year - pd.to_datetime(banking[\"birth_date\"]).dt.year\n",
    "\n",
    "# Find rows where age column == ages_manual\n",
    "age_equ = banking[\"age\"] == ages_manual\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_ages = banking[age_equ]\n",
    "inconsistent_ages = banking[~age_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent ages: \", inconsistent_ages.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Completeness"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Completeness\n",
    "\n",
    "Hi and welcome to the last lesson of this chapter. In this lesson, we're going to discuss completeness and missing data."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. What is missing data?\n",
    "\n",
    "Missing data is one of the most common and most important data cleaning problems. Essentially, missing data is when no data value is stored for a variable in an observation. Missing data is most commonly represented as NA or NaN, but can take on arbitrary values like 0 or dot. Like a lot of the problems that we've seen thus far in the course, it's commonly due to technical or human errors. Missing data can take many forms, so let's take a look at an example."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Airquality example\n",
    "\n",
    "Let's take a look at the airquality dataset. It contains temperature and CO2 measurements for different dates."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Airquality example\n",
    "\n",
    "We can see that the CO2 value in this row is represented as NaN"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. Airquality example\n",
    "\n",
    "We can find rows with missing values by using the dot is na method, which returns True for missing values and False for complete values across all our rows and columns."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. Airquality example\n",
    "\n",
    "We can also chain the isna method with the sum method, which returns a breakdown of missing values per column in our dataframe. We notice that the CO2 column is the only column with missing values - let's find out why and dig further into the nature of this missingness by first visualizing our missing values."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. Missingno\n",
    "\n",
    "The missingno package allows to create useful visualizations of our missing data. Digging into its details is not part of the course, but you can also check out other courses on missing data in DataCamp's course library. We visualize the missingness of the airquality DataFrame with the msno dot matrix function, and show it with pyplot's show function from matplotlib, which returns"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. Insert title here...\n",
    "\n",
    "the following image. This matrix essentially shows how missing values are distributed across a column. We see that missing CO2 values are randomly scattered throughout the column, but is that really the case? Let's dig deeper."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. Airquality example\n",
    "\n",
    "We first isolate the rows of airquality with missing CO2 values in one DataFrame, and complete CO2 values in another."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. Airquality example\n",
    "\n",
    "Then, let's use the describe method on each of the created DataFrames."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 11. Airquality example\n",
    "\n",
    "We see that for all missing values of CO2, they occur at really low temperatures, with the mean temperature at minus 39 degrees and a minimum and maximum of -49 and -30 respectively. Let's confirm this visually with the missngno package."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 12. Insert title here...\n",
    "\n",
    "We first sort the DataFrame by the temperature column. Then we input the sorted dataframe to the matrix function from msno. This leaves us with this matrix."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 13. Insert title here...\n",
    "\n",
    "Notice how all missing values are on the top? This is because values are sorted from smallest to largest by default. This essentially confirms that CO2 measurements are lost for really low temperatures. Must be a sensor failure!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 14. Missingness types\n",
    "\n",
    "This leads us to missingness types. Without going too much into the details, there are a variety of types of missing data. It could missing completely at random, missing at random, or missing not at random."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 15. Missingness types\n",
    "\n",
    "Missing completely at random data is when there missing data completely due to randomness, and there is no relationship between missing data and remaining values, such data entry errors."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 16. Missingness types\n",
    "\n",
    "Despite a slightly deceiving name, Missing at random data is when there is a relationship between missing data and other observed values, such as our CO2 data being missing for low temperatures."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 17. Missingness types\n",
    "\n",
    "When data is missing not at random, there is a systematic relationship between the missing data and unobserved values. For example, when it's really hot outside, the thermometer might stop working, so we don't have temperature measurements for days with high temperatures. However, we have no way to tell this just from looking at the data since we can't actually see what the missing temperatures are."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 18. How to deal with missing data?\n",
    "\n",
    "There's a variety of ways of dealing with missing data, from dropping missing data, to imputing them with statistical measures such as mean, median or mode, or imputing them with more complicated algorithmic approaches or ones that require some machine learning. Each missingness type requires a specific approach, and each type of approach has drawbacks and positives, so make sure to dig deeper in DataCamp's course library on dealing with missing data."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 19. Dealing with missing data\n",
    "\n",
    "In this lesson, we'll just explore the simple approaches to dealing with missing data. Let's grab another look at the header of airquality."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 20. Dropping missing values\n",
    "\n",
    "We can drop missing values, by using the dot dropna method, alongside the subset argument which lets us pick which column's missing values to drop."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 21. Replacing with statistical measures\n",
    "\n",
    "We can also replace the missing values of CO2 with the mean value of CO2, by using the fillna method, which is in this case 1.73. Fillna takes in a dictionary with columns as keys, and the imputed value as values. We can even feed custom values into fillna pertaining to our missing data if we have enough domain knowledge about our dataset."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 22. Let's practice!\n",
    "\n",
    "Now that you know how to tackle missing data, let's get started!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Missing investors\n",
    "\n",
    "<p>Dealing with missing data is one of the most common tasks in data science. There are a variety of types of missingness, as well as a variety of types of solutions to missing data.</p>\n",
    "<p>You just received a new version of the <code>banking</code> DataFrame containing data on the amount held and invested for new and existing customers. However, there are rows with missing <code>inv_amount</code> values. </p>\n",
    "<p>You know for a fact that most customers below 25 do not have investment accounts yet, and suspect it could be driving the missingness. The <code>pandas</code>, <code>missingno</code> and <code>matplotlib.pyplot</code> packages have been imported as <code>pd</code>, <code>msno</code> and <code>plt</code> respectively. The <code>banking</code> DataFrame is in your environment.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "banking = pd.read_csv(\"data/banking_miss.csv\",index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Print the number of missing values by column in the <code>banking</code> DataFrame."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Plot and show the missingness matrix of <code>banking</code> with the <code>msno.matrix()</code> function."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cust_id              0\n",
      "age                  0\n",
      "acct_amount          0\n",
      "inv_amount          13\n",
      "account_opened       0\n",
      "last_transaction     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1800x720 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print number of missing values in banking\n",
    "print(banking.isna().sum())\n",
    "\n",
    "# Visualize missingness matrix\n",
    "msno.matrix(banking)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "# Isolate missing and non missing values of inv_amount\n",
    "missing_investors = banking[banking[\"inv_amount\"].isna()]\n",
    "investors = banking[~banking[\"inv_amount\"].isna()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "             age   acct_amount  inv_amount\ncount  13.000000     13.000000         0.0\nmean   21.846154  73231.238462         NaN\nstd     1.519109  25553.327176         NaN\nmin    20.000000  21942.370000         NaN\n25%    21.000000  66947.300000         NaN\n50%    21.000000  86028.480000         NaN\n75%    23.000000  89855.980000         NaN\nmax    25.000000  99998.350000         NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>acct_amount</th>\n      <th>inv_amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>13.000000</td>\n      <td>13.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>21.846154</td>\n      <td>73231.238462</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.519109</td>\n      <td>25553.327176</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>20.000000</td>\n      <td>21942.370000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>21.000000</td>\n      <td>66947.300000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>21.000000</td>\n      <td>86028.480000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>23.000000</td>\n      <td>89855.980000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>25.000000</td>\n      <td>99998.350000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_investors.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "             age    acct_amount    inv_amount\ncount  84.000000      84.000000     84.000000\nmean   43.559524   75095.273214  44717.885476\nstd    10.411244   32414.506022  26031.246094\nmin    26.000000   12209.840000   3216.720000\n25%    34.000000   57373.062500  22736.037500\n50%    45.000000   83061.845000  44498.460000\n75%    53.000000   94165.965000  66176.802500\nmax    59.000000  250046.760000  93552.690000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>acct_amount</th>\n      <th>inv_amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>84.000000</td>\n      <td>84.000000</td>\n      <td>84.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>43.559524</td>\n      <td>75095.273214</td>\n      <td>44717.885476</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10.411244</td>\n      <td>32414.506022</td>\n      <td>26031.246094</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>26.000000</td>\n      <td>12209.840000</td>\n      <td>3216.720000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>34.000000</td>\n      <td>57373.062500</td>\n      <td>22736.037500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>45.000000</td>\n      <td>83061.845000</td>\n      <td>44498.460000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>53.000000</td>\n      <td>94165.965000</td>\n      <td>66176.802500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>59.000000</td>\n      <td>250046.760000</td>\n      <td>93552.690000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investors.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "The inv_amount is missing only for young customers, since the average age in missing_investors is 22 and the maximum age is 25."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1800x720 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort banking by age and visualize\n",
    "banking_sorted = banking.sort_values(\"age\")\n",
    "msno.matrix(banking_sorted)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Follow the money\n",
    "\n",
    "<p>In this exercise, you're working with another version of the <code>banking</code> DataFrame that contains missing values for both the <code>cust_id</code> column and the <code>acct_amount</code> column. </p>\n",
    "<p>You want to produce analysis on how many unique customers the bank has, the average amount held by customers and more. You know that rows with missing <code>cust_id</code> don't really help you, and that on average <code>acct_amount</code> is usually 5 times the amount of <code>inv_amount</code>. </p>\n",
    "<p>In this exercise, you will drop rows of <code>banking</code> with missing <code>cust_id</code>s, and impute missing values of <code>acct_amount</code> with some domain knowledge.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "banking = pd.read_csv(\"data/banking_missing_amt.csv\",index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Use <code>.dropna()</code> to drop missing values of the <code>cust_id</code> column in <code>banking</code> and store the results in <code>banking_fullid</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cust_id              9\n",
      "acct_amount         14\n",
      "inv_amount           0\n",
      "account_opened       0\n",
      "last_transaction     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print number of missing values\n",
    "print(banking.isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "# Drop missing values of cust_id\n",
    "banking_fullid = banking.dropna(subset = ['cust_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use <code>inv_amount</code> to compute the estimated account amounts for <code>banking_fullid</code> by setting the amounts equal to <code>inv_amount * 5</code>, and assign the results to <code>acct_imp</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "\n",
    "# Compute estimated acct_amount\n",
    "acct_imp = banking_fullid[\"inv_amount\"] *5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Impute the missing values of <code>acct_amount</code> in <code>banking_fullid</code> with the newly created <code>acct_imp</code> using <code>.fillna()</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cust_id             0\n",
      "acct_amount         0\n",
      "inv_amount          0\n",
      "account_opened      0\n",
      "last_transaction    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing acct_amount with corresponding acct_imp\n",
    "banking_imputed = banking_fullid.fillna({'acct_amount':acct_imp})\n",
    "\n",
    "# Print number of missing values\n",
    "print(banking_imputed.isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# Record linkage"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Comparing strings"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Comparing strings\n",
    "\n",
    "Awesome work on chapter 3! Welcome to the final chapter of this course,"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. In this chapter\n",
    "\n",
    "where we'll discover the world of record linkage. But before we get deep dive into record linkage, let's sharpen our understanding of string similarity and minimum edit distance."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Minimum edit distance\n",
    "\n",
    "Minimum edit distance is a systematic way to identify how close 2 strings are. For example, let's take a look at the following two words: intention, and execution. The minimum edit distance between them is the least possible amount of steps, that could get us from the word intention to execution, with the available operations being"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### 4. Minimum edit distance\n",
    "\n",
    "inserting new characters, deleting them, substituting them, and transposing consecutive characters.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"image/img_9.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. Minimum edit distance\n",
    "\n",
    "To get from intention to execution,"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. Minimum edit distance\n",
    "\n",
    "We first start off by deleting I from intention, and adding C between E and N. Our minimum edit distance so far is 2, since these are two operations."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. Minimum edit distance\n",
    "\n",
    "Then we substitute the first N with E, T with X, and N with U, leading us to execution! With the minimum edit distance being 5."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. Minimum edit distance\n",
    "\n",
    "The lower the edit distance, the closer two words are. For example, the two different typos of reading have a minimum edit distance of 1 between them and reading."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. Minimum edit distance algorithms\n",
    "\n",
    "There's a variety of algorithms based on edit distance that differ on which operations they use, how much weight attributed to each operation, which type of strings they're suited for and more, with a variety of packages to get each similarity."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. Minimum edit distance algorithms\n",
    "\n",
    "For this lesson, we'll be comparing strings using Levenshtein distance since it's the most general form of string matching by using the fuzzywuzzy package.\n",
    "\n",
    "<img src=\"image/img_10.png\">"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4 5 6]\n",
      " [1 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0]\n",
      " [3 0 0 0 0 0 0]\n",
      " [4 0 0 0 0 0 0]\n",
      " [5 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "dummy = np.zeros((6,7),dtype=int)\n",
    "dummy[0,:] = np.arange(7)\n",
    "dummy[:,0] = np.arange(6)\n",
    "print(dummy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "def levenshtein_algorithm(s,t):\n",
    "    rows = len(s)+1\n",
    "    cols = len(t)+1\n",
    "    distance = np.zeros((rows,cols),dtype=int)\n",
    "    distance[0,:] = np.arange(cols)\n",
    "    distance[:,0] = np.arange(rows)\n",
    "\n",
    "    for col in range(1,cols):\n",
    "        for row in range(1,rows):\n",
    "            if s[row-1] == t[col-1]:\n",
    "                distance[row,col] = distance[row-1,col-1]\n",
    "            else:\n",
    "                distance[row,col] = min(distance[row-1,col],distance[row-1,col-1],distance[row,col-1]) + 1\n",
    "\n",
    "\n",
    "    return distance[row,col]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "distance = levenshtein_algorithm(Str1,Str2)\n",
    "distance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 11. Simple string comparison\n",
    "\n",
    "Fuzzywuzzy is a simple to use package to perform string comparison. We first import fuzz from fuzzywuzzy, which allow us to compare between single strings. Here we use fuzz's WRatio function to compute the similarity between reading and its typo, inputting each string as an argument. For any comparison function using fuzzywuzzy, our output is a score from 0 to 100 with 0 being not similar at all, 100 being an exact match. Do not confuse this with the minimum edit distance score earlier, where a lower minimum edit distance means a closer match."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "86"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "fuzz.WRatio(\"Reeding\",\"Reading\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 12. Partial strings and different orderings\n",
    "\n",
    "The WRatio function is highly robust against partial string comparison with different orderings. For example here we compare the strings Houston Rockets and Rockets, and still receive a high similarity score. The same can be said for the strings Houston Rockets vs Los Angeles Lakers and Lakers vs Rockets, where the team names are only partial and they are differently ordered."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "90"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.WRatio(\"Houston Rockets\",\"Rockets\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "data": {
      "text/plain": "86"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.WRatio(\"Houston Rockets vs Los Angeles Lakers\",\"Lakers vs Rockets\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 13. Comparison with arrays\n",
    "\n",
    "We can also compare a string with an array of strings by using the extract function from the process module from fuzzy wuzzy. Extract takes in a string, an array of strings, and the number of possible matches to return ranked from highest to lowest. It returns a list of tuples with 3 elements, the first one being the matching string being returned, the second one being its similarity score, and the third one being its index in the array."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Rockets vs Lakers', 86, 0), ('Lakers vs Rockets', 86, 1)]"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"Houston Rockets vs Los Angeles Lakers\"\n",
    "choices = pd.Series(['Rockets vs Lakers', 'Lakers vs Rockets', 'Houson vs Los Angeles' , 'Heat vs Bulls'])\n",
    "\n",
    "process.extract(string,choices,limit=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 14. Collapsing categories with string similarity\n",
    "\n",
    "In chapter 2, we learned that collapsing data into categories is an essential aspect of working with categorical and text data, and we saw how to manually replace categories in a column of a DataFrame. But what if we had so many inconsistent categories that a manual replacement is simply not feasible? We can easily do that with string similarity!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 15. Collapsing categories with string matching\n",
    "\n",
    "Say we have DataFrame named survey containing answers from respondents from the state of New York and California asking them how likely are you to move on a scale of 0 to 5. The state field was free text and contains hundreds of typos. Remapping them manually would take a huge amount of time. Instead, we'll use string similarity. We also have a category DataFrame containing the correct categories for each state. Let's collapse the incorrect categories with string matching!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 16. Collapsing all of the state\n",
    "\n",
    "We first create a for loop iterating over each correctly typed state in the categories DataFrame. For each state, we find its matches in the state column of the survey DataFrame, returning all possible matches by setting the limit argument of extract to the length of the survey DataFrame. Then we iterate over each potential match, isolating the ones only with a similarity score higher or equal than 80 with an if statement. Then for each of those returned strings, we replace it with the correct state using the loc method."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 17. Record linkage\n",
    "\n",
    "Record linkage attempts to join data sources that have similarly fuzzy duplicate values, so that we end up with a final DataFrame with no duplicates by using string similarity. We'll cover record linkage in more detail in the next couple of lessons."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 18. Let's practice!\n",
    "\n",
    "But for now, let's clean some data using string similarity!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## The cutoff point\n",
    "\n",
    "<p>In this exercise, and throughout this chapter, you'll be working with the <code>restaurants</code> DataFrame which has data on various restaurants. Your ultimate goal is to create a restaurant recommendation engine, but you need to first clean your data. </p>\n",
    "<p>This version of <code>restaurants</code> has been collected from many sources, where the <code>cuisine_type</code> column is riddled with typos, and should contain only <code>italian</code>, <code>american</code> and <code>asian</code> cuisine types. There are so many unique categories that remapping them manually isn't scalable, and it's best to use string similarity instead. </p>\n",
    "<p>Before doing so, you want to establish the cutoff point for the similarity score using the <code>fuzzywuzzy</code>'s <code>process.extract()</code> function by finding the similarity score of the most <em>distant</em> typo of each category.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "restaurants = pd.read_csv(\"data/restaurants_collapse.csv\",index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Import <code>process</code> from <code>fuzzywuzzy</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Store the unique <code>cuisine_type</code>s into <code>unique_types</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['america', 'merican', 'amurican', 'americen', 'americann',\n       'asiane', 'itali', 'asiann', 'murican', 'italien', 'italian',\n       'asiat', 'american', 'americano', 'italiann', 'ameerican',\n       'asianne', 'italiano', 'americin', 'ammericann', 'amerycan',\n       'aamerican', 'ameriican', 'italiaan', 'asiian', 'asiaan',\n       'amerrican', 'ameerrican', 'ammereican', 'asian', 'italianne',\n       'italiian', 'itallian'], dtype=object)"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_types = restaurants[\"cuisine_type\"].unique()\n",
    "unique_types"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Calculate the similarity of <code>'asian'</code>, <code>'american'</code>, and <code>'italian'</code> to all possible <code>cuisine_type</code>s using <code>process.extract()</code>, while returning all possible matches."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "[('italian', 100),\n ('italiann', 93),\n ('italiano', 93),\n ('italiaan', 93),\n ('italiian', 93),\n ('itallian', 93),\n ('italianne', 88),\n ('italien', 86),\n ('itali', 83),\n ('asian', 67),\n ('asiane', 62),\n ('asiann', 62),\n ('asiian', 62),\n ('asiaan', 62),\n ('asianne', 57),\n ('amurican', 53),\n ('american', 53),\n ('americann', 50),\n ('asiat', 50),\n ('americano', 50),\n ('ameerican', 50),\n ('aamerican', 50),\n ('ameriican', 50),\n ('amerrican', 50),\n ('ammericann', 47),\n ('ameerrican', 47),\n ('ammereican', 47),\n ('america', 43),\n ('merican', 43),\n ('murican', 43),\n ('americen', 40),\n ('americin', 40),\n ('amerycan', 40)]"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract(\"italian\",unique_types,limit=len(unique_types))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "[('american', 100),\n ('americann', 94),\n ('americano', 94),\n ('ameerican', 94),\n ('aamerican', 94),\n ('ameriican', 94),\n ('amerrican', 94),\n ('america', 93),\n ('merican', 93),\n ('ammericann', 89),\n ('ameerrican', 89),\n ('ammereican', 89),\n ('amurican', 88),\n ('americen', 88),\n ('americin', 88),\n ('amerycan', 88),\n ('murican', 80),\n ('asian', 62),\n ('asiane', 57),\n ('asiann', 57),\n ('asiian', 57),\n ('asiaan', 57),\n ('italian', 53),\n ('asianne', 53),\n ('italiann', 50),\n ('italiano', 50),\n ('italiaan', 50),\n ('italiian', 50),\n ('itallian', 50),\n ('italianne', 47),\n ('asiat', 46),\n ('itali', 40),\n ('italien', 40)]"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract(\"american\",unique_types,limit=len(unique_types))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "[('asian', 100),\n ('asiane', 91),\n ('asiann', 91),\n ('asiian', 91),\n ('asiaan', 91),\n ('asianne', 83),\n ('asiat', 80),\n ('italiann', 72),\n ('italiano', 72),\n ('italianne', 72),\n ('italian', 67),\n ('amurican', 62),\n ('american', 62),\n ('italiaan', 62),\n ('italiian', 62),\n ('itallian', 62),\n ('americann', 57),\n ('americano', 57),\n ('ameerican', 57),\n ('aamerican', 57),\n ('ameriican', 57),\n ('amerrican', 57),\n ('ammericann', 54),\n ('ameerrican', 54),\n ('ammereican', 54),\n ('america', 50),\n ('merican', 50),\n ('murican', 50),\n ('italien', 50),\n ('americen', 46),\n ('americin', 46),\n ('amerycan', 46),\n ('itali', 40)]"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract(\"asian\",unique_types,limit=len(unique_types))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can choose the cutoff point as 80 , when wratio > 80 all the word collapse into similar category"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Remapping categories II\n",
    "\n",
    "<p>In the last exercise, you determined that the distance cutoff point for remapping typos of <code>'american'</code>, <code>'asian'</code>, and <code>'italian'</code> cuisine types stored in the <code>cuisine_type</code> column should be 80. </p>\n",
    "<p>In this exercise, you're going to put it all together by finding matches with similarity scores equal to or higher than 80 by using <code>fuzywuzzy.process</code>'s <code>extract()</code> function, for each correct cuisine type, and replacing these matches with it. Remember, when comparing a string with an array of strings using <code>process.extract()</code>, the output is a list of tuples where each is formatted like:</p>\n",
    "<pre><code>(closest match, similarity score, index of match)\n",
    "</code></pre>\n",
    "<p>The <code>restaurants</code> DataFrame is in your environment, and you have access to a <code>categories</code> list containing the correct cuisine types (<code>'italian'</code>, <code>'asian'</code>, and <code>'american'</code>).</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Return all of the unique values in the <code>cuisine_type</code> column of <code>restaurants</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "categories = [\"italian\",\"asian\",\"american\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['america' 'merican' 'amurican' 'americen' 'americann' 'asiane' 'itali'\n",
      " 'asiann' 'murican' 'italien' 'italian' 'asiat' 'american' 'americano'\n",
      " 'italiann' 'ameerican' 'asianne' 'italiano' 'americin' 'ammericann'\n",
      " 'amerycan' 'aamerican' 'ameriican' 'italiaan' 'asiian' 'asiaan'\n",
      " 'amerrican' 'ameerrican' 'ammereican' 'asian' 'italianne' 'italiian'\n",
      " 'itallian']\n"
     ]
    }
   ],
   "source": [
    "print(restaurants[\"cuisine_type\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american' 'asian' 'italian']\n"
     ]
    }
   ],
   "source": [
    "for cuisine in categories:\n",
    "    matches = process.extract(cuisine,restaurants[\"cuisine_type\"],limit=len(restaurants.cuisine_type))\n",
    "    for match in matches:\n",
    "        if match[1] >= 80:\n",
    "            restaurants.loc[restaurants[\"cuisine_type\"] == match[0] ,\"cuisine_type\"] = cuisine\n",
    "\n",
    "print(restaurants[\"cuisine_type\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Generating pairs"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Generating pairs\n",
    "\n",
    "Great work with lesson 1 - you now have a solid understanding how to calculate string similarity."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. Motivation\n",
    "\n",
    "At the end of the last video exercise, we saw how record linkage attempts to join data sources with fuzzy duplicate values. For example here are two DataFrames containing NBA games and their schedules. They've both been scraped from different sites and we would want to merge them together and have one DataFrame containing all unique games."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. When joins won't work\n",
    "\n",
    "We see that there are duplicates values in both DataFrames with different naming marked here in red, and non duplicate values, marked here in green. Since there are games happening at the same time, no common unique identifier between the DataFrames, and the events are differently named, a regular join or merge will not work. This is where record linkage comes in."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Record linkage\n",
    "\n",
    "Record linkage is the act of linking data from different sources regarding the same entity. Generally, we clean two or more DataFrames, generate pairs of potentially matching records, score these pairs according to string similarity and other similarity metrics, and link them. All of these steps can be achieved with the recordlinkage package, let's find how!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. Our DataFrames\n",
    "\n",
    "Here we have two DataFrames, census_A, and census_B, containing data on individuals throughout the states. We want to merge them while avoiding duplication using record linkage, since they are collected manually and are prone to typos, there are no consistent IDs between them."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. Generating pairs\n",
    "\n",
    "We first want to generate pairs between both DataFrames. Ideally, we want to generate all possible pairs between our DataFrames."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. Generating pairs\n",
    "\n",
    "but what if we had big DataFrames and ended up having to generate millions if not billions of pairs? It wouldn't prove scalable and could seriously hamper development time."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. Blocking\n",
    "\n",
    "This is where we apply what we call blocking, which creates pairs based on a matching column, which is in this case, the state column, reducing the number of possible pairs."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. Generating pairs\n",
    "\n",
    "To do this, we first start off by importing recordlinkage. We then use the recordlinkage dot Index function, to create an indexing object. This essentially is an object we can use to generate pairs from our DataFrames. To generate pairs blocked on state, we use the block method, inputting the state column as input. Once the indexer object has been initialized, we generate our pairs using the dot index method, which takes in the two dataframes."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. Generating pairs\n",
    "\n",
    "The resulting object, is a pandas multi index object containing pairs of row indices from both DataFrames, which is a fancy way to say it is an array containing possible pairs of indices that makes it much easier to subset DataFrames on."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 11. Comparing the DataFrames\n",
    "\n",
    "Since we've already generated our pairs, it's time to find potential matches. We first start by creating a comparison object using the recordlinkage dot compare function. This is similar to the indexing object we created while generating pairs, but this one is responsible for assigning different comparison procedures for pairs. Let's say there are columns for which we want exact matches between the pairs. To do that, we use the exact method. It takes in the column name in question for each DataFrame, which is in this case date_of_birth and state, and a label argument which lets us set the column name in the resulting DataFrame. Now in order to compute string similarities between pairs of rows for columns that have fuzzy values, we use the dot string method, which also takes in the column names in question, the similarity cutoff point in the threshold argument, which takes in a value between 0 and 1, which we here set to 0.85. Finally to compute the matches, we use the compute function, which takes in the possible pairs, and the two DataFrames in question. Note that you need to always have the same order of DataFrames when inserting them as arguments when generating pairs, comparing between columns, and computing comparisons."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 12. Finding matching pairs\n",
    "\n",
    "The output is a multi index DataFrame, where the first index is the row index from the first DataFrame, or census A, and the second index is a list of all row indices in census B. The columns are the columns being compared, with values being 1 for a match, and 0 for not a match."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 13. Finding the only pairs we want\n",
    "\n",
    "To find potential matches, we just filter for rows where the sum of row values is higher than a certain threshold. Which in this case higher or equal to 2. But we'll dig deeper into these matches and see how to use them to link our census DataFrames in the next lesson."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 14. Let's practice!\n",
    "\n",
    "But for now, let's generate pairs."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Pairs of restaurants\n",
    "\n",
    "<p>In the last lesson, you cleaned the <code>restaurants</code> dataset to make it ready for building a restaurants recommendation engine. You have a new DataFrame named <code>restaurants_new</code> with new restaurants to train your model on, that's been scraped from a new data source. </p>\n",
    "<p>You've already cleaned the <code>cuisine_type</code> and <code>city</code> columns using the techniques learned throughout the course. However you saw duplicates with typos in restaurants names that require record linkage instead of joins with <code>restaurants</code>.</p>\n",
    "<p>In this exercise, you will perform the first step in record linkage and generate possible pairs of rows between <code>restaurants</code> and <code>restaurants_new</code>. Both DataFrames, <code>pandas</code> and <code>recordlinkage</code> are in your environment.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "import recordlinkage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "restaurants_new = pd.read_csv(\"data/restaurants_collapse_new.csv\",index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Instantiate an indexing object by using the <code>Index()</code> function from <code>recordlinkage</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "indexer = recordlinkage.Index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Block your pairing on <code>cuisine_type</code> by using <code>indexer</code>'s' <code>.block()</code> method."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "<Index>"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.block(\"cuisine_type\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Generate pairs by indexing <code>restaurants</code> and <code>restaurants_new</code> in that order."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "pairs = indexer.index(restaurants,restaurants_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Similar restaurants\n",
    "\n",
    "<p>In the last exercise, you generated pairs between <code>restaurants</code> and <code>restaurants_new</code> in an effort to cleanly merge both DataFrames using record linkage.</p>\n",
    "<p>When performing record linkage, there are different types of matching you can perform between different columns of your DataFrames, including exact matches, string similarities, and more.</p>\n",
    "<p>Now that your pairs have been generated and stored in <code>pairs</code>, you will find exact matches in the <code>city</code> and <code>cuisine_type</code> columns between each pair, and similar strings for each pair in the <code>rest_name</code> column. Both DataFrames, <code>pandas</code> and <code>recordlinkage</code> are in your environment.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Instantiate a comparison object using the <code>recordlinkage.Compare()</code> function."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        city  cuisine_type  name\n",
      "11  14     0             1   0.0\n",
      "    21     1             1   1.0\n",
      "    47     0             1   0.0\n",
      "    57     0             1   0.0\n",
      "    73     0             1   0.0\n",
      "...      ...           ...   ...\n",
      "330 79     0             1   0.0\n",
      "334 26     0             1   0.0\n",
      "    65     0             1   0.0\n",
      "    71     0             1   0.0\n",
      "    79     0             1   0.0\n",
      "\n",
      "[3063 rows x 3 columns]\n",
      "        city  cuisine_type  name\n",
      "11  14     0             1   0.0\n",
      "    21     1             1   1.0\n",
      "    47     0             1   0.0\n",
      "    57     0             1   0.0\n",
      "    73     0             1   0.0\n",
      "...      ...           ...   ...\n",
      "330 79     0             1   0.0\n",
      "334 26     0             1   0.0\n",
      "    65     0             1   0.0\n",
      "    71     0             1   0.0\n",
      "    79     0             1   0.0\n",
      "\n",
      "[3063 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "comp_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches on city, cuisine_types\n",
    "comp_cl.exact('city', 'city', label='city')\n",
    "comp_cl.exact('cuisine_type', 'cuisine_type', label = 'cuisine_type')\n",
    "\n",
    "# Find similar matches of rest_name\n",
    "comp_cl.string('rest_name', 'rest_name', label='name', threshold = .8)\n",
    "# Get potential matches and print\n",
    "potential_matches = comp_cl.compute(pairs, restaurants, restaurants_new)\n",
    "print(potential_matches)\n",
    "\n",
    "# Get potential matches and print\n",
    "potential_matches = comp_cl.compute(pairs, restaurants, restaurants_new)\n",
    "print(potential_matches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Linking DataFrames"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 1. Linking DataFrames\n",
    "\n",
    "Awesome work on the first 2 lessons! You've made it to the last lesson of this course!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 2. Record linkage\n",
    "\n",
    "At this point, you've generated your pairs, compared them, and scored them."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 3. Record linkage\n",
    "\n",
    "Now it's time to link your data!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4. Our DataFrames\n",
    "\n",
    "Remember our census DataFrames from the video of the previous lesson?"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 5. What we've already done\n",
    "\n",
    "We've already generated pairs between them, compared four of their columns, two for exact matches and two for string similarity alongside a 0.85 threshold, and found potential matches."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 6. What we're doing now\n",
    "\n",
    "Now it's time to link both census DataFrames."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 7. Our potential matches\n",
    "\n",
    "Let's look closely at our potential matches. It is a multi-index DataFrame, where we have two index columns, record id 1, and record id 2."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 8. Our potential matches\n",
    "\n",
    "The first index column, stores indices from census A."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 9. Our potential matches\n",
    "\n",
    "The second index column, stores all possible indices from census_B, for each row index of census_A."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 10. Our potential matches\n",
    "\n",
    "The columns of our potential matches are the columns we chose to link both DataFrames on, where the value is 1 for a match, and 0 otherwise."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 11. Probable matches\n",
    "\n",
    "The first step in linking DataFrames, is to isolate the potentially matching pairs to the ones we're pretty sure of. We saw how to do this in the previous lesson, by subsetting the rows where the row sum is above a certain number of columns, in this case 3. The output is row indices between census A and census B that are most likely duplicates. Our next step is to extract the one of the index columns, and subsetting its associated DataFrame to filter for duplicates."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 12. Probable matches\n",
    "\n",
    "Here we choose the second index column, which represents row indices of census B. We want to extract those indices, and subset census_B on them to remove duplicates with census_A before appending them together."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 13. Get the indices\n",
    "\n",
    "We can access a DataFrame's index using the index attribute. Since this is a multi index DataFrame, it returns a multi index object containing pairs of row indices from census_A and census_B respectively. We want to extract all census_B indices, so we chain it with the get_level_values method, which takes in which column index we want to extract its values. We can either input the index column's name, or its order, which is in this case 1."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 14. Linking DataFrames\n",
    "\n",
    "To find the duplicates in census B, we simply subset on all indices of census_B, with the ones found through record linkage. You can choose to examine them further for similarity with their duplicates in census_A, but if you're sure of your analysis, you can go ahead and find the non duplicates by repeating the exact same line of code, except by adding a tilde at the beginning of your subset. Now that you have your non duplicates, all you need is a simple append using the DataFrame append method of census A, and you have your linked Data!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 15. Linking DataFrames\n",
    "\n",
    "To recap, what we did was build on top of our previous work in generating pairs, comparing across columns and finding potential matches. We then isolated all possible matches, where there are matches across 3 columns or more, ensuring we tightened our search for duplicates across both DataFrames before we link them. Extracted the row indices of census_B where there are duplicates. Found rows of census_B where they are not duplicated with census_A by using the tilde symbol. And linked both DataFrames for full census results!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "### 16. Let's practice!\n",
    "\n",
    "Now that you know how to link DataFrames, let's put those skills to action!"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "## Linking them together!\n",
    "\n",
    "<p>In the last lesson, you've finished the bulk of the work on your effort to link <code>restaurants</code> and <code>restaurants_new</code>. You've generated the different pairs of potentially matching rows, searched for exact matches between the <code>cuisine_type</code> and <code>city</code> columns, but compared for similar strings in the <code>rest_name</code> column. You stored the DataFrame containing the scores in <code>potential_matches</code>.</p>\n",
    "<p>Now it's finally time to link both DataFrames. You will do so by first extracting all row indices of <code>restaurants_new</code> that are matching across the columns mentioned above from <code>potential_matches</code>. Then you will subset <code>restaurants_new</code> on these indices, then append the non-duplicate values to <code>restaurants</code>. All DataFrames are in your environment, alongside <code>pandas</code> imported as <code>pd</code>.</p>"
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Isolate instances of <code>potential_matches</code> where the row sum is above or equal to 3 by using the <code>.sum()</code> method."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "matches = potential_matches[potential_matches.sum(axis=1) >=3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Extract the second column index from <code>matches</code>, which represents row indices of matching record from <code>restaurants_new</code> by using the <code>.get_level_values()</code> method."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "matching_indices = matches.index.get_level_values(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Subset <code>restaurants_new</code> for rows that are not in <code>matching_indices</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "non_dup = restaurants_new[~restaurants_new.index.isin(matching_indices)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "Append <code>non_dup</code> to <code>restaurants</code>."
   ],
   "execution_count": null,
   "cell_type": "markdown"
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     rest_name                  rest_addr               city  \\\n",
      "0   arnie morton  s of chicago   435 s. la cienega blv .         los angeles   \n",
      "1          art  s delicatessen       12224 ventura blvd.         studio city   \n",
      "2                    campanile       624 s. la brea ave.         los angeles   \n",
      "3                        fenix    8358 sunset blvd. west           hollywood   \n",
      "4           grill on the alley           9560 dayton way         los angeles   \n",
      "..                         ...                        ...                ...   \n",
      "77                       feast        1949 westwood blvd.            west la   \n",
      "78                    mulberry        17040 ventura blvd.             encino   \n",
      "79                  matsuhissa   129 n. la cienega blvd.       beverly hills   \n",
      "80                     jiraffe      502 santa monica blvd       santa monica   \n",
      "81                    martha's  22nd street grill 25 22nd  st. hermosa beach   \n",
      "\n",
      "         phone cuisine_type  \n",
      "0   3102461501      america  \n",
      "1   8187621221      merican  \n",
      "2   2139381447     amurican  \n",
      "3   2138486677     americen  \n",
      "4   3102760615    americann  \n",
      "..         ...          ...  \n",
      "77  3104750400      chinese  \n",
      "78  8189068881        pizza  \n",
      "79  3106599639        asian  \n",
      "80  3109176671  californian  \n",
      "81  3103767786     american  \n",
      "\n",
      "[367 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_13260\\955763288.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  full_restaurants = restaurants.append(non_dup)\n"
     ]
    }
   ],
   "source": [
    "full_restaurants = restaurants.append(non_dup)\n",
    "print(full_restaurants)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}